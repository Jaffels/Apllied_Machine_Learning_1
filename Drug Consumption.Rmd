---
title: "Drug Consumption"
author: "Nhat Bui, Johan Ferreira, Thilo Holstein"
date: "2025-03-06"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    fig_width: 7
    fig_height: 5
    fig_caption: true
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  cache = TRUE,
  fig.align = "center"
)
```

\newpage

# Introduction

Drug use is a significant risk behavior with serious health consequences for individuals and society. Multiple factors contribute to initial drug use, including psychological, social, individual, environmental, and economic elements, as well as personality traits. While legal substances like sugar, alcohol, and tobacco cause more premature deaths, illegal recreational drugs still create substantial social and personal problems.

In this data science project, we aim to identify factors and patterns potentially explaining drug use behaviors through machine learning techniques. By analyzing demographic, psychological, and social variables in our dataset, we'll aim to uncover potential predictors using machine learning methods to understand the complex relationships surrounding drug consumption.

The database contains records for 1,885 respondents with 12 attributes including personality measurements (NEO-FFI-R, BIS-11, ImpSS), demographics (education, age, gender, country, ethnicity), and self-reported usage of 18 drugs plus one fictitious drug (Semeron). Drug use is classified into seven categories ranging from "Never Used" to "Used in Last Day." All input attributes are quantified as real values, creating 18 distinct classification problems corresponding to each drug. A detailed description of the variables can be found in the Column Decsription text file.

# Personality Traits Explanation

To better understand the data set we need to have an understanding of what the personality traits are and what they represent, below we have a short description of each trait and how to interpret them:

-   Nscore (Neuroticism): Measures emotional stability vs. instability. Higher scores indicate tendency toward negative emotions like anxiety, depression, vulnerability and mood swings. Lower scores suggest emotional stability and resilience to stress.
-   Escore (Extraversion): Measures sociability and outgoingness. Higher scores indicate preference for social interaction, assertiveness, and energy in social settings. Lower scores suggest preference for solitude, quieter environments and more reserved behavior.
-   Oscore (Openness to Experience): Measures intellectual curiosity and creativity. Higher scores indicate imagination, appreciation for art/beauty, openness to new ideas, and unconventional thinking. Lower scores suggest preference for routine, practicality, and conventional approaches.
-   Ascore (Agreeableness): Measures concern for social harmony. Higher scores indicate empathy, cooperation, and consideration for others. Lower scores suggest competitive, skeptical, or challenging interpersonal styles.
-   Cscore (Conscientiousness): Measures organization and reliability. Higher scores indicate discipline, responsibility, planning, and detail orientation. Lower scores suggest spontaneity, flexibility, and potentially less structured approaches.
-   Impulsive (Impulsiveness): Measures tendency to act without thinking. Higher scores indicate spontaneous decision-making without considering consequences. Lower scores suggest thoughtful deliberation before actions.
-   SS (Sensation Seeking): Measures desire for novel experiences and willingness to take risks. Higher scores indicate thrill-seeking behavior and preference for excitement. Lower scores suggest preference for familiarity and safety.

The first five traits (Nscore through Cscore) are the "Big Five" personality traits, which are widely used in psychological research. The Impulsive and SS measures are additional traits that are often studied in relation to risk-taking behaviors, which makes sense given our dataset includes variables related to substance use.

# Cleaning and Formatting the Dataset

```{r include=FALSE, cache=FALSE}
# Load required libraries
library(broom)
library(caret)
library(car)
library(DALEX)
library(e1071)
library(factoextra)
library(FactoMineR)
library(fmsb)
library(GGally)
library(ggplot2)
library(grid)
library(gridExtra)
library(here)
library(iml)
library(janitor)
library(kableExtra)
library(knitr)
library(lattice)
library(MASS)
library(mgcv)
library(neuralnet)
library(NeuralNetTools)
library(parallel)
library(reshape2)
library(tibble)
library(tidyr)
library(tidyverse)
library(dplyr)

# Suppresses all warnings
options(warn = -1)
```

```{r echo=FALSE, cache=TRUE}
# Read the CSV file
drug_data <- read.csv("Data/drug_consumption.csv")
```

## Data Formatting

In its original state, the dataset represented most categorical variables with random floating-point numbers. We believe this was a measure to mitigate bias within the dataset. However, as our project's objectives differ from the dataset's initial purpose, we needed to revert these encoded values back to their original categorical representations. This step was essential to perform the analyses required for our project. This was the first step in cleaning our dataset.

```{r fom1, echo=FALSE, cache=TRUE}
###############################################################################
# Define mappings and column information
###############################################################################

# Column names for the dataset
column_names <- c(
  "Index", "ID", "Age", "Gender", "Education", "Country", "Ethnicity", 
  "Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive", "SS", 
  "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis", "Choc", "Coke", 
  "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh", "LSD", "Meth", 
  "Mushrooms", "Nicotine", "Semer", "VSA"
)

# Drug column names
drug_columns <- c(
  "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis", 
  "Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", 
  "Legalh", "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA"
)

# Mapping of drug consumption classes to their meanings
consumption_mapping <- c(
  "CL0" = "Never Used",
  "CL1" = "Used over a Decade Ago",
  "CL2" = "Used in Last Decade", 
  "CL3" = "Used in Last Year",
  "CL4" = "Used in Last Month",
  "CL5" = "Used in Last Week",
  "CL6" = "Used in Last Day"
)

# Map Age values to their meaning
age_mapping <- c(
  "-0.95197" = "18-24",
  "-0.07854" = "25-34",
  "0.49788" = "35-44",
  "1.09449" = "45-54",
  "1.82213" = "55-64",
  "2.59171" = "65+"
)

# Map Gender values to their meaning
gender_mapping <- c(
  "0.48246" = "Female",
  "-0.48246" = "Male"
)

# Map Education values to their meaning
education_mapping <- c(
  "-2.43591" = "Left school before 16 years",
  "-1.73790" = "Left school at 16 years",
  "-1.43719" = "Left school at 17 years",
  "-1.22751" = "Left school at 18 years",
  "-0.61113" = "Some college or university, no certificate or degree",
  "-0.05921" = "Professional certificate/diploma",
  "0.45468" = "University degree",
  "1.16365" = "Masters degree",
  "1.98437" = "Doctorate degree"
)

# Map Country values to their meaning
country_mapping <- c(
  "-0.09765" = "Australia",
  "0.24923" = "Canada",
  "-0.46841" = "New Zealand",
  "-0.28519" = "Other",
  "0.21128" = "Republic of Ireland",
  "0.96082" = "UK",
  "-0.57009" = "USA"
)

# Map Ethnicity values to their meaning
ethnicity_mapping <- c(
  "-0.50212" = "Asian",
  "-1.10702" = "Black",
  "1.90725" = "Mixed-Black/Asian",
  "0.12600" = "Mixed-White/Asian",
  "-0.22166" = "Mixed-White/Black",
  "0.11440" = "Other",
  "-0.31685" = "White"
)
```

```{r fom2, echo=FALSE, cache=TRUE}
###############################################################################
# Data Processing
###############################################################################

# Rename the columns 
colnames(drug_data) <- column_names

# Convert demographic columns to descriptive values
drug_data$Age <- age_mapping[as.character(drug_data$Age)]
drug_data$Gender <- gender_mapping[as.character(drug_data$Gender)]
drug_data$Education <- education_mapping[as.character(drug_data$Education)]
drug_data$Country <- country_mapping[as.character(drug_data$Country)]
drug_data$Ethnicity <- ethnicity_mapping[as.character(drug_data$Ethnicity)]

# Convert all drug consumption columns to descriptive values
for (col in drug_columns) {
  drug_data[[col]] <- consumption_mapping[as.character(drug_data[[col]])]
}
```

## Investigating Missing Values

```{r fom3, echo=FALSE, cache=TRUE}
###############################################################################
# Data Cleaning - Missing values
###############################################################################

# Remove unnecessary column
drug_data <- drug_data[, -which(names(drug_data) == "ID")]

# Check for NA values in each column
na_by_column <- sapply(drug_data, function(x) sum(is.na(x)))

# Create a data frame for better table formatting
na_df <- data.frame(
  Column = names(na_by_column)[na_by_column > 0],
  NA_Count = na_by_column[na_by_column > 0],
  Percentage = round(na_by_column[na_by_column > 0] / nrow(drug_data) * 100, 2)
)

# Create a nicely formatted table with kable
na_table <- na_df %>%
  kable(caption = "Missing Values by Column",
        booktabs = TRUE,
        col.names = c("Column", "Missing Values", "Percentage (%)"),
        digits = c(0, 0, 2),
        align = c('l', 'r', 'r')) %>%
  kable_styling(latex_options = c("striped", "hold_position"),
                full_width = FALSE,
                position = "center") %>%
  row_spec(0, bold = TRUE) %>%
  footnote(
    general = "Only columns with missing values are shown.",
    footnote_as_chunk = TRUE
  )

# Display the table
na_table
```

In the second step, we addressed missing values. We found that only two columns contained missing data, affecting approximately 5% of the 1885 observations. Considering the nature of these variables and the completeness of the remaining data, we inferred that participants likely withheld this information deliberately in most instances. Consequently, we replaced these missing values with the label "Not Provided," enabling us to treat these cases as a distinct category in our analysis.

```{r fom4, echo=FALSE, cache=TRUE}
# Replace NA values with "Not Provided"
drug_data$Education[is.na(drug_data$Education)] <- "Not Provided"
drug_data$Ethnicity[is.na(drug_data$Ethnicity)] <- "Not Provided"

# Save the updated dataframe back to CSV
write.csv(drug_data, "Data/cleaned.csv")
```

## Investigating Outliers

```{r fom5, echo=FALSE, cache=TRUE, fig.width=5, fig.height=4}
###############################################################################
# Data Cleaning - Looking for outliers
###############################################################################
# Define numeric columns for outlier analysis
numeric_cols <- c("Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive", "SS")

# Function to identify outliers using IQR method
identify_outliers_iqr <- function(x) {
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  q3 <- quantile(x, 0.75, na.rm = TRUE)
  iqr <- q3 - q1
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  
  return(data.frame(
    min = min(x, na.rm = TRUE),
    q1 = q1,
    median = median(x, na.rm = TRUE),
    mean = mean(x, na.rm = TRUE),
    q3 = q3,
    max = max(x, na.rm = TRUE),
    iqr = iqr,
    lower_bound = lower_bound,
    upper_bound = upper_bound,
    n_outliers_below = sum(x < lower_bound, na.rm = TRUE),
    n_outliers_above = sum(x > upper_bound, na.rm = TRUE),
    total_outliers = sum(x < lower_bound | x > upper_bound, na.rm = TRUE),
    outlier_percentage = round(100 * sum(x < lower_bound | x > upper_bound, na.rm = TRUE) / length(x[!is.na(x)]), 2)
  ))
}

# Apply outlier detection to all numeric columns
outlier_summary <- data.frame()
for (col in numeric_cols) {
  result <- identify_outliers_iqr(drug_data[[col]])
  result$variable <- col
  outlier_summary <- rbind(outlier_summary, result)
}

# Create a function to visualize outliers with boxplots
plot_outliers <- function(drug_data, columns) {
  # Explicitly use reshape2::melt to avoid namespace issues
  melted_data <- reshape2::melt(drug_data[, columns], id.vars = NULL)
  
  # Create boxplot
  ggplot(melted_data, aes(x = variable, y = value)) +
    geom_boxplot(outlier.colour = "red", outlier.shape = 16, outlier.size = 2) +
    theme_minimal() +
    labs(title = "Boxplots with Outliers Highlighted",
         x = "Variable",
         y = "Value") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

# Visualize outliers
plot_outliers(drug_data, numeric_cols)
```

The box plots generated for the seven psychometric personality scores reveal some data points that lie beyond the conventional 1.5xIQR (Interquartile Range) whiskers, technically identifying them as outliers. After invetigating the outliers we establised that outliers is not extreme in nature and fall within a plausible range, as well as being infrequent. Critically, their presence does not appear to significantly distort the overall distributional characteristics of these personality measures, which is important for subsequent analyses. The general cleanliness of the dataset, including the limited impact of these outliers, was better than anticipated, leading us to suspect that it may have undergone some form of pre-processing or curation before we accessed it.

# Exploratory Data Analysis

## Correlation between Behavioral Measures

```{r da1, echo=FALSE, cache=TRUE, fig.width=5, fig.height=4}
###############################################################################
# Heatmap
###############################################################################

# Calculate the correlation matrix
cor_matrix <- cor(drug_data[numeric_cols], use = "pairwise.complete.obs")

# Convert the correlation matrix to a data frame for ggplot
cor_df <- melt(cor_matrix)
names(cor_df) <- c("Var1", "Var2", "Correlation")

# Create a ggplot2 correlation heatmap
ggplot(data = cor_df, aes(x = Var1, y = Var2, fill = Correlation)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  geom_text(aes(label = round(Correlation, 2)), color = "black", size = 3) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  ) +
  coord_fixed() +
  labs(
    title = "Correlation Matrix Behavioral Measures",
    x = "",
    y = ""
  )
```

The correlation matrix reveals that certain personality traits tend to cluster. For instance, Sensation Seeking (SS) shows a positive correlation with Extraversion (Escore), Openness (Oscore), and Impulsiveness. These three traits (Extraversion, Openness, and Impulsiveness) are also positively correlated with each other. Conversely, Sensation Seeking (along with Extraversion, Openness, and Impulsiveness) exhibits a negative correlation with Conscientiousness (Cscore) and Agreeableness (Ascore). Finally, Conscientiousness and Agreeableness demonstrate a positive correlation with each other.

## Comparing Behavioral Measure for Gender

```{r da2, echo=FALSE, cache=TRUE, fig.width=5, fig.height=4}
###############################################################################
# Gender comparison
###############################################################################

# Calculating the means of the behavioral scores
gender_results <- data.frame(
  Trait = character(),
  Female_Mean = numeric(),
  Male_Mean = numeric(),
  stringsAsFactors = FALSE
)

for (col in numeric_cols) {
  # Calculate means only
  female_mean <- mean(drug_data[drug_data$Gender == "Female", col], na.rm = TRUE)
  male_mean <- mean(drug_data[drug_data$Gender == "Male", col], na.rm = TRUE)
  
  # Add to results dataframe with only needed values
  gender_results <- rbind(gender_results, data.frame(
    Trait = col,
    Female_Mean = female_mean,
    Male_Mean = male_mean,
    stringsAsFactors = FALSE
  ))
}

# Create readable trait names
gender_results$Trait_Name <- case_when(
  gender_results$Trait == "Nscore" ~ "Neuroticism",
  gender_results$Trait == "Escore" ~ "Extraversion",
  gender_results$Trait == "Oscore" ~ "Openness",
  gender_results$Trait == "Ascore" ~ "Agreeableness",
  gender_results$Trait == "Cscore" ~ "Conscientiousness",
  gender_results$Trait == "Impulsive" ~ "Impulsivity",
  gender_results$Trait == "SS" ~ "Sensation Seeking",
  TRUE ~ gender_results$Trait
)

# Create the plot directly from the results
ggplot(gender_results, aes(x = Trait_Name)) +
  geom_bar(aes(y = Female_Mean, fill = "Female"), stat = "identity", position = "dodge", width = 0.7, alpha = 0.7) +
  geom_bar(aes(y = Male_Mean, fill = "Male"), stat = "identity", position = position_dodge(width = 0.7), width = 0.7, alpha = 0.7) +
  scale_fill_manual(values = c("Female" = "#FF9999", "Male" = "#6699CC"),
                    name = "Gender") +
  labs(title = "Gender Differences in Behavioral Measures",
       x = "",
       y = "Mean Score") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        plot.title = element_text(hjust = 0.5, size = 14),
        legend.position = "top") +
  # Fixed axis limits from -0.25 to 0.25
  scale_y_continuous(limits = c(-0.25, 0.25)) +
  coord_flip()
```

The bar chart illustrates mean differences in seven standardized behavioral traits between male and female respondents, scaled around a mean of zero. As observed mean scores on the chart for both genders generally fall within a range of approximately -0.25 to 0.25.

Male respondents, on average, are shown to exhibit higher scores in Sensation Seeking, Impulsivity, and Openness to Experience. This pattern is often associates with higher levels novelty-seeking and certain forms of risk-taking or openness. Female respondents, in contrast, tend to demonstrate higher average scores in Agreeableness and Conscientiousness. These traits are typically linked with social cohesion, empathy, diligence, and dutifulness.

## Analysis of Seremon Usage

```{r da4, echo=FALSE, cache=TRUE}
###############################################################################
# Seremon
###############################################################################

# Count Semeron users vs non-users
semeron_counts <- drug_data %>%
  group_by(Semer) %>%
  summarise(Count = n()) %>%
  arrange(desc(Count))
```

```{r da5, problem_chuck, echo=FALSE, cache=TRUE}
# Create a nicely formatted table for the detailed counts
semeron_table <- semeron_counts %>%
  mutate(Percentage = paste0(round(Count / sum(Count) * 100, 2), "%")) %>%
  rename(`Usage Category` = Semer) %>%
  kable(caption = "Semeron Usage Categories", 
        booktabs = TRUE, 
        col.names = c("Usage Category", "Count", "Percentage"))

# For PDF output, apply specific styling
if(knitr::is_latex_output()) {
  semeron_table <- semeron_table %>%
    kable_styling(latex_options = c("striped", "hold_position"), 
                  full_width = FALSE,
                  position = "center") %>%
    row_spec(0, bold = TRUE) %>%
    column_spec(1, width = "5cm") %>%
    column_spec(2, width = "2cm") %>%
    column_spec(3, width = "2.5cm")
}

# Display the table
semeron_table
```

The questionnaire included Semeron a fictitious drug. The fact that only a very small fraction of participants, 0.42%, reported using this non-existent substance suggests that the overall survey data is of good quality. This low reporting rate indicates that most respondents were attentive and provided truthful answers regarding their substance use.

## Personality Traits by Marijuana Use

```{r glmbi_intro, echo=FALSE, cache=TRUE}
# Load the dataset
df <- read.csv("Data/model_data.csv")
#Remove the first column index X
df_cnb <- df[,-1]
# Create a column to flag if ever used cannabis
df_cnb <- df_cnb %>%
  mutate(
    cnb_use = if_else(Cannabis == 0, 0, 1)
  )
```

```{r glmbi_boxplot, echo=FALSE, cache=TRUE, fig.width=5, fig.height=3}
# Boxplots by use status
trait_labs <- c(
  Nscore = "Neuroticism",
  Escore = "Extraversion",
  Oscore = "Openness",
  Ascore = "Agreeableness",
  Cscore = "Conscientiousness"
)
df_cnb %>%
  gather(trait, score, Nscore:Cscore) %>%
  ggplot(aes(x = factor(cnb_use), y = score)) +
    geom_boxplot() +
    facet_wrap(
      ~ trait, 
      scales = "free_y", 
      ncol = 5, 
      labeller = labeller(trait = trait_labs)) +
    scale_x_discrete(labels = c("Never", "Ever")) +
    labs(x = "Marijuana Use", y = "Trait Score",
         title = "Personality Traits by Marijuana Use")
```
The boxplots show a clear pattern across several traits when comparing people who’ve never tried marijuana to those who have. Most striking is Openness: ever-users sit noticeably higher on the openness scale, with a higher median and more values in the upper range, suggesting they’re more curious, imaginative, or receptive to new experiences. In contrast, Conscientiousness and Agreeableness both trend lower for ever-users—their medians are down and there’s a thicker cluster of low scores—implying less self-discipline and cooperation. Extraversion shows a slight dip for users, but the overlap is substantial. Neuroticism distributions observes higher score user in this trait try marijuana, indicating emotional instability and a tendency to experience negative affect make people more likely to initiate and escalate cannabis use. Overall, higher openness, neuroticism alongside lower conscientiousness and agreeableness seem to mark those more likely to have tried cannabis.

## Overall age-use curve

```{r age-use curve, echo=FALSE, cache=TRUE, fig.width=4.5, fig.height=3}
# Load cleaned dataset
df_cl <- read.csv("Data/cleaned.csv")
# Remove the X column
if("X" %in% names(df_cl)) df_cl <- df_cl %>% select(-X)
# Classify past-year cannabis use: if use cannabis in the past year, then 1, otherwise 0 
past_year_labels <- c(
  "Used in Last Year",
  "Used in Last Month",
  "Used in Last Week",
  "Used in Last Day"
)
df_cnb_gam <- df_cl %>%
  mutate(
    cnb_use = case_when(
      Cannabis %in% past_year_labels           ~ "Yes",
      Cannabis %in% c("Never Used",
                      "Used over a Decade Ago",
                      "Used in Last Decade")  ~ "No",
      TRUE                                     ~ NA_character_
    ),
    cnb_use = factor(cnb_use, levels = c("No","Yes"))
  )

age_levels <- c("18-24", "25-34", "35-44", "45-54", "55-64", "65+")
df_cnb_gam <- df_cnb_gam %>%
  mutate(
    age_cat = factor(Age, levels = age_levels, ordered = TRUE),
    # numeric midpoint (as rough continuous proxy)
    age_mid = case_when(
      age_cat == "18-24" ~ 21,
      age_cat == "25-34" ~ 29.5,
      age_cat == "35-44" ~ 39.5,
      age_cat == "45-54" ~ 49.5,
      age_cat == "55-64" ~ 59.5,
      age_cat == "65+"   ~ 70,
      TRUE ~ NA_real_
    )
  )
df_cnb_gam %>%
  group_by(age_cat) %>%
  summarise(pct_use = mean(cnb_use == "Yes") * 100,
            n = n()) %>%
  ggplot(aes(x = age_cat, y = pct_use, group = 1)) +
    geom_point(aes(size = n)) +
    geom_line() +
    labs(x = "Age group", y = "Past-year cannabis use (%)",
         title = "Overall age–use curve")
```

The age‐use curve paints a striking picture of how past‐year cannabis consumption shifts across the lifespan. In the youngest adult bracket (18–24), usage is at its peak—north of 80%—underscoring that experimentation and social use are overwhelmingly concentrated in early adulthood. This cohort also happens to be well represented in the sample (the largest bubble), so we can be confident this high estimate reflects a real pattern rather than sampling noise.

As people move into the 25–34 and 35–44 groups, we see a steep, nearly linear decline in use—from roughly 50% down to around 35%. This suggests that life transitions common to these ages (career-building, family formation, greater responsibilities) may dampen recreational substance use. By middle age (45–54), prevalence dips further to about 25%, illustrating a continued retreat from cannabis as adults settle into longer‐term routines.

Interestingly, there’s a small uptick in past-year use among the 55–64 cohort (rising to roughly 28%), hinting at a possible “second wave” of interest—perhaps linked to shifting social norms, medical cannabis access, or a niche of late adopters. Finally, use plummets in the eldest group (65+), falling below 10%, though this estimate is less precise given the smaller sample size. Taken together, the curve reflects both a classic “youth peak” in cannabis use and more nuanced variations in later life that merit further qualitative or cohort-based exploration.

# Prepraring the Dataset for Machine Learning

```{r prep1, echo=FALSE, cache=TRUE}
################################################################################
# Prep the data for modeling
################################################################################

# Make a copy of the dataset
model_data <- drug_data

# Remove the fake drug Semeron and index column
model_data <- model_data %>% 
  select(-c(Semer, Index))

# Map drug levels
consumption_levels <- c(
  "Never Used" = 0,
  "Used over a Decade Ago" = 1,
  "Used in Last Decade" = 2,
  "Used in Last Year" = 3,
  "Used in Last Month" = 4,
  "Used in Last Week" = 5,
  "Used in Last Day" = 6
)

# Iterate through each specified drug column
for (col_name in drug_columns) {
  if (col_name %in% names(model_data)) {
    column_values_as_char <- as.character(model_data[[col_name]])
    model_data[[col_name]] <- unname(consumption_levels[column_values_as_char])
  } 
}

# Convert gender to binary encoding
model_data$Gender <- ifelse(model_data$Gender == "Male", 1, 0)

# Change Age levels to ordinal
age_levels <- c("18-24", "25-34", "35-44", "45-54", "55-64", "65+")
model_data$Age <- as.integer(factor(model_data$Age, levels = age_levels))

# Change Education levels to ordinal
education_levels <- c(
  "Not Provided",
  "Left school before 16 years",
  "Left school at 16 years",
  "Left school at 17 years",
  "Left school at 18 years",
  "Some college or university, no certificate or degree",
  "Professional certificate/diploma",
  "University degree",
  "Masters degree",
  "Doctorate degree"
)
model_data$Education <- as.integer(factor(model_data$Education, levels = education_levels))

# Country - One-hot Encoding
country <- model.matrix(~ Country - 1, data = model_data)
model_data <- cbind(model_data, country)

# Ethnicity - One-hot Encoding
ethnicity <- model.matrix(~ Ethnicity - 1, data = model_data)
model_data <- cbind(model_data, ethnicity)

# Remove the original columns
model_data <- model_data %>% select(-c(Country, Ethnicity))

# Save the updated dataframe to csv
write.csv(model_data, "Data/model_data.csv")
```

Since the main focus of the project is implementing machine learning models we decided to prepare our data for this purpose. Just like we converted our original dataset to be more human readable for data exploration we have changed our dataset dataset to be more machine readable. The sex column was changed to binary data and for all the Drug columns, Education and Age we converted the data to ordinal data.

For the Ethnicity and Country columns we used a technique called One-Hot Encoding, where we transforms a categorical variable with multiple possible values into multiple binary (0 or 1) columns. Each new column represents one possible category from the original variable, and for each observation, exactly one of these new columns will have the value 1 (hence "one-hot") while all others will be 0.

It prevents the machine learning algorithm from assuming an arbitrary numerical relationship between categories. For example, if you simply encoded "USA"=1, "UK"=2, "Canada"=3, the algorithm might incorrectly assume that "Canada" is somehow "greater than" or "three times more important than" "USA".

# Machine Learning Models

## Linear Model (Johan Ferreira)

Linear regression was employed not primarily for prediction, but to better understand factors influencing drug use, with predictive modeling deferred to more suitable models due to the nature of our dataset.

```{r lr1, echo=FALSE, cache=TRUE}

# Read the processed dataset
model_data <- read.csv("Data/model_data.csv")

# Remove the first index column if it exists
if(names(model_data)[1] == "X") {
  model_data <- model_data[,-1]
}

#---------------------------------------------------------------
# Linear Regression Modeling
#---------------------------------------------------------------

# Create clean names for drugs to analyze
drug_names <- c("Cannabis", "Alcohol", "Nicotine", "Coke", "Ecstasy")

# Function to build and evaluate linear regression model
run_drug_regression <- function(data, drug_name) {
  # Formula creation - all features, but handle multicollinearity in categorical variables
  
  # For country variables, exclude one as reference (USA)
  country_vars <- grep("Country", names(data), value = TRUE)
  country_vars <- country_vars[country_vars != "CountryUSA"] # Use USA as reference
  
  # For ethnicity variables, exclude one as reference (White)
  ethnicity_vars <- grep("Ethnicity", names(data), value = TRUE)
  ethnicity_vars <- ethnicity_vars[ethnicity_vars != "EthnicityWhite"] # Use White as reference
  
  # Create formula with modified variables to avoid perfect multicollinearity
  formula_str <- paste(drug_name, "~ Age + Gender + Education + Nscore + Escore + Oscore + Ascore + Cscore + Impulsive + SS + ", 
                     paste(c(country_vars, ethnicity_vars), collapse = " + "))
  
  formula <- as.formula(formula_str)
  
  # Fit model
  model <- lm(formula, data = data)
  
  # Check VIF for multicollinearity
  # First check if the model has aliased coefficients
  alias_check <- alias(model)
  has_aliased <- length(alias_check$Complete) > 0
  
  # Only run VIF if no aliased coefficients
  if(!has_aliased) {
    vif_values <- vif(model)
    high_vif <- vif_values[vif_values > 5]
  } else {
    # If there are aliased coefficients, we can't calculate VIF
    vif_values <- "Aliased coefficients detected"
    high_vif <- "Aliased coefficients detected"
    
    # Get the names of the aliased coefficients
    aliased_names <- rownames(alias_check$Complete)
    cat("Aliased coefficients detected in model for", drug_name, ":", paste(aliased_names, collapse=", "), "\n")
  }
  
  # Optional: Step-wise selection for feature selection
  # step_model <- step(model, direction = "both")
  
  # Return model and diagnostics
  return(list(
    model = model,
    summary = summary(model),
    vif = vif_values,
    high_vif = high_vif
  ))
}

# Create a results container
results_list <- list()

# Run regression for selected drugs
for (drug in drug_names) {
  # Check if the drug exists in the dataset
  if (drug %in% names(model_data)) {
    results_list[[drug]] <- run_drug_regression(model_data, drug)
  } else {
    cat("Warning: Drug", drug, "not found in dataset\n")
  }
}
```

```{r lr2, echo=FALSE, cache=TRUE}
#---------------------------------------------------------------
# Model Comparison and Visualization
#---------------------------------------------------------------

# Function to create a summary table of model performance
create_model_summary_table <- function(results_list) {
  # Initialize empty data frame
  summary_df <- data.frame(
    Drug = character(),
    R_squared = numeric(),
    Adj_R_squared = numeric(),
    F_statistic = numeric(),
    P_value = numeric(),
    Top_positive_predictor = character(),
    Top_negative_predictor = character(),
    stringsAsFactors = FALSE
  )
  
  # Fill with results
  for (drug in names(results_list)) {
    model_summary <- results_list[[drug]]$summary
    
    # Get coefficients
    coefs <- model_summary$coefficients
    
    # Find top predictors (excluding intercept)
    coef_df <- data.frame(
      Variable = rownames(coefs)[-1],
      Estimate = coefs[-1, "Estimate"],
      P_value = coefs[-1, "Pr(>|t|)"]
    )
    
    # Get significant predictors only
    sig_coefs <- coef_df[coef_df$P_value < 0.05, ]
    
    if(nrow(sig_coefs) > 0) {
      # Get top positive and negative predictors
      top_pos <- sig_coefs[which.max(sig_coefs$Estimate), "Variable"]
      top_neg <- sig_coefs[which.min(sig_coefs$Estimate), "Variable"]
    } else {
      top_pos <- "None"
      top_neg <- "None"
    }
    
    # Add to summary
    summary_df <- rbind(summary_df, data.frame(
      Drug = drug,
      R_squared = model_summary$r.squared,
      Adj_R_squared = model_summary$adj.r.squared,
      F_statistic = model_summary$fstatistic[1],
      P_value = pf(model_summary$fstatistic[1], 
                 model_summary$fstatistic[2], 
                 model_summary$fstatistic[3], 
                 lower.tail = FALSE),
      Top_positive_predictor = top_pos,
      Top_negative_predictor = top_neg,
      stringsAsFactors = FALSE
    ))
  }
  
  return(summary_df)
}

# Create and format the summary table
model_summary_table <- create_model_summary_table(results_list)
```

```{r lr3, echo=FALSE, cache=TRUE}
#---------------------------------------------------------------
# Linear Regression Plots
#---------------------------------------------------------------

# Function to create a visually appealing coefficient plot
# MODIFIED to display only a specific list of predictors
plot_factor_importance_enhanced <- function(model, title, color_scheme = "viridis") {
  # Extract model coefficients
  coefs <- summary(model)$coefficients
  
  # Filter out intercept and create data frame for plotting
  coef_df <- data.frame(
    Variable = rownames(coefs)[-1],  # Exclude intercept
    Estimate = coefs[-1, "Estimate"],
    StdError = coefs[-1, "Std. Error"],
    PValue = coefs[-1, "Pr(>|t|)"]
  )
  
  # Add significance markers and categories
  coef_df$Significance <- ifelse(coef_df$PValue < 0.001, "p < 0.001", 
                               ifelse(coef_df$PValue < 0.01, "p < 0.01",
                                    ifelse(coef_df$PValue < 0.05, "p < 0.05", "Not significant")))
  
  # --- START MODIFICATION: Filter for specific predictors ---
  # Define the specific predictors (raw model variable names) to display
  target_predictors_raw_names <- c("Age", "Gender", "Education", 
                                   "Nscore", "Escore", "Oscore", 
                                   "Ascore", "Cscore", "Impulsive", "SS")
  
  # Filter coef_df to include only these target predictors
  # This ensures only the specified variables appear on the y-axis
  coef_df <- coef_df[coef_df$Variable %in% target_predictors_raw_names, ]
  
  # If no target predictors are found in the model (e.g., model is empty or different),
  # prevent errors by stopping if coef_df is empty.
  if(nrow(coef_df) == 0) {
    warning(paste("No target predictors found in the model for:", title, ". Plot will be empty or may error."))
    # Optionally, return an empty plot or a message plot
    # return(ggplot() + labs(title = title, subtitle = "No target predictors to display") + theme_void())
  }
  # --- END MODIFICATION ---

  # Sort by absolute value of estimate (among the selected predictors)
  coef_df <- coef_df[order(abs(coef_df$Estimate), decreasing = TRUE), ]
  
  # The line to keep only top 15 predictors is removed as we are explicitly selecting.
  # if(nrow(coef_df) > 15) {
  #   coef_df <- coef_df[1:15, ]
  # }
  
  # Clean up variable names for display
  # This mapping should ideally only contain the target_predictors_raw_names for clarity,
  # but the filtering above is the primary control.
  var_display_mapping <- c(
    "Age" = "Age",
    "Gender" = "Gender (Male=1)",
    "Education" = "Education Level",
    "Nscore" = "Neuroticism",
    "Escore" = "Extraversion",
    "Oscore" = "Openness",
    "Ascore" = "Agreeableness",
    "Cscore" = "Conscientiousness",
    "Impulsive" = "Impulsivity",
    "SS" = "Sensation Seeking"
    # Country and Ethnicity mappings are still here but won't be used
    # if those variables are filtered out by target_predictors_raw_names.
  )
  
  # Function to clean up variable names
  clean_var_names <- function(var_name) {
    if (var_name %in% names(var_display_mapping)) {
      return(var_display_mapping[var_name])
    }
    # Fallback for other variable types (e.g., one-hot encoded if they were part of the target list)
    if (grepl("^Country", var_name)) {
      return(gsub("Country", "Country: ", var_name))
    }
    if (grepl("^Ethnicity", var_name)) {
      return(gsub("Ethnicity", "Ethnicity: ", var_name))
    }
    return(var_name) # Return original name if no mapping found
  }
  
  # Apply name cleaning
  coef_df$DisplayName <- sapply(coef_df$Variable, clean_var_names)
  
  # Reorder factor levels for plotting (so highest absolute estimate among selected is at the top)
  coef_df$DisplayName <- factor(coef_df$DisplayName, levels = rev(coef_df$DisplayName))
  
  # Define significance color palette
  if (color_scheme == "viridis") {
    sig_colors <- c("p < 0.001" = "#440154", "p < 0.01" = "#21908C", 
                    "p < 0.05" = "#5DC863", "Not significant" = "#CCCCCC")
  } else {
    sig_colors <- c("p < 0.001" = "#0072B2", "p < 0.01" = "#009E73", 
                    "p < 0.05" = "#56B4E9", "Not significant" = "#CCCCCC")
  }
  
  # Plot with enhanced aesthetics
  p <- ggplot(coef_df, aes(x = Estimate, y = DisplayName, color = Significance)) +
    geom_point(aes(size = abs(Estimate)), alpha = 0.8) +
    geom_errorbarh(aes(xmin = Estimate - 1.96 * StdError, 
                       xmax = Estimate + 1.96 * StdError), 
                   height = 0.2, alpha = 0.7) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "darkgray", linewidth = 0.7) +
    scale_color_manual(values = sig_colors) +
    scale_size_continuous(range = c(2, 6), guide = "none") + # guide="none" hides size legend
    labs(title = title,
         x = "Effect Size (Coefficient Estimate)",
         y = "", # Y-axis label not needed as variable names are clear
         color = "Statistical\nSignificance") +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
      axis.title.x = element_text(size = 12, face = "bold"),
      axis.text.y = element_text(size = 10), # Ensure y-axis text is readable
      legend.position = "top",
      legend.title = element_text(face = "bold"),
      panel.grid.minor = element_blank(),
      panel.grid.major.y = element_blank() # Removing horizontal grid lines for cleaner look
    )
  return(p)
}
```

### Personality Traits as Predictors of Substance Use

```{r lr5, echo=FALSE, cache=TRUE, fig.width=5, fig.height=4}
#---------------------------------------------------------------
# Generate Output
#---------------------------------------------------------------

# Create a publication-quality regression table using kable instead of stargazer
# for more reliable operation

# Function to create clean model coefficient table
create_model_coef_table <- function(model_list, drug_names) {
  # Extract key coefficients from each model
  key_vars <- c("Age", "Gender", "Education", "Nscore", "Escore",
               "Oscore", "Ascore", "Cscore", "Impulsive", "SS")

  # Create data frame for results
  result_df <- data.frame(
    Variable = c("(Intercept)", key_vars),
    stringsAsFactors = FALSE
  )

  # Add each model's coefficients and significance
  for (drug in drug_names) {
    if (drug %in% names(model_list)) {
      model <- model_list[[drug]]$model
      coefs <- summary(model)$coefficients

      # Extract coefficients and p-values
      drug_coefs <- numeric(length(result_df$Variable))
      drug_p <- numeric(length(result_df$Variable)) # p-values still extracted but not used for stars

      for (i in 1:length(result_df$Variable)) {
        var_name <- result_df$Variable[i]
        if (var_name %in% rownames(coefs)) {
          drug_coefs[i] <- coefs[var_name, "Estimate"]
          drug_p[i] <- coefs[var_name, "Pr(>|t|)"]
        } else {
          drug_coefs[i] <- NA
          drug_p[i] <- NA
        }
      }

      # Format coefficients (without significance stars)
      drug_coef_text <- ifelse(!is.na(drug_coefs),
                             sprintf("%.3f", round(drug_coefs, 3)), # drug_sig (stars) removed from here
                             "")

      # Add to result dataframe
      result_df[[drug]] <- drug_coef_text
    }
  }

  # Add model metrics
  metrics_rows <- data.frame(
    Variable = c("N", "R²", "Adjusted R²", "F-statistic"),
    stringsAsFactors = FALSE
  )

  for (drug in drug_names) {
    if (drug %in% names(model_list)) {
      model_summary <- summary(model_list[[drug]]$model)
      n <- length(model_summary$residuals)
      r2 <- model_summary$r.squared
      adj_r2 <- model_summary$adj.r.squared
      f_stat <- model_summary$fstatistic[1]

      metrics_rows[[drug]] <- c(
        as.character(n),
        sprintf("%.3f", round(r2, 3)),
        sprintf("%.3f", round(adj_r2, 3)),
        sprintf("%.3f", round(f_stat, 3))
      )
    }
  }

  # Combine results and metrics
  final_df <- rbind(result_df, metrics_rows)

  # Clean variable names for display
  var_display_names <- c(
    "(Intercept)" = "Intercept",
    "Age" = "Age",
    "Gender" = "Gender (Male=1)",
    "Education" = "Education Level",
    "Nscore" = "Neuroticism",
    "Escore" = "Extraversion",
    "Oscore" = "Openness",
    "Ascore" = "Agreeableness",
    "Cscore" = "Conscientiousness",
    "Impulsive" = "Impulsivity",
    "SS" = "Sensation Seeking",
    "N" = "N",
    "R²" = "R²",
    "Adjusted R²" = "Adjusted R²",
    "F-statistic" = "F-statistic"
  )

  final_df$Variable <- var_display_names[final_df$Variable]

  return(final_df)
}


# Create the comparison table for the main drugs
drug_names_for_table <- names(results_list)
if (length(drug_names_for_table) > 0) {
  model_comparison_table <- create_model_coef_table(
    results_list,
    drug_names_for_table
  )

  # Display the table with kable for better formatting
  kable(model_comparison_table,
      caption = "Linear Regression Models for Drug Usage",
      align = c('l', rep('r', ncol(model_comparison_table) - 1)),
      longtable = TRUE) %>%
    kable_styling(
      latex_options = c("striped", "hold_position"), 
      full_width = FALSE,
      position = "center"                             
    ) %>%
    row_spec(0, bold = TRUE) %>%                      
    column_spec(1, bold = TRUE) %>%                   
    add_header_above(c(" " = 1, "Drug Models" = ncol(model_comparison_table) - 1))
} else {
  cat("No valid drug models to display in table\n")
}
```

Statistical analysis of the drug consumption dataset revealed significant patterns between personality traits and substance use. Linear regression models for substances like Cannabis, Alcohol, and Nicotine showed that Cannabis had the most robust predictive model (highest adjusted R²). Sensation Seeking (SS) and Impulsivity consistently showed strong positive correlations with multi-drug use, while Conscientiousness and Agreeableness had significant negative relationships. Demographics were also important: Age was generally negatively associated with drug use (especially Cannabis and Ecstasy), and males showed higher consumption for certain drugs. Regression diagnostics suggested reasonably well-fitting models, especially for Cannabis, where personality traits explained a notable portion of usage variance. These results align with suggestions that certain personality profiles, particularly high Sensation Seeking, predispose individuals to substance use.

### Analysis of Personality Traits for Cannabis use

```{r lr6, echo=FALSE, cache=TRUE, fig.width=6, fig.height=3.5}

# Properly define the individual models for plotting
if ("Cannabis" %in% names(results_list)) {
  cannabis_model <- results_list[["Cannabis"]]$model
  cannabis_coef_plot <- plot_factor_importance_enhanced(cannabis_model, "Predictors of Cannabis Usage")
  print(cannabis_coef_plot)
}
```

**Cannabis Usage Predictors**

The first plot presents the predictors of cannabis usage, showing estimated coefficients with 95% confidence intervals. Several key observations emerge:

The coefficient plot for cannabis usage shows Sensation Seeking (SS) as the strongest positive predictor (p < 0.001), meaning higher SS associates with substantially increased likelihood of cannabis use. Age has a strong negative association (p < 0.001), with use decreasing significantly as age increases. Openness (Oscore) is another significant positive predictor (p < 0.001), linking intellectual curiosity to higher cannabis use. Neuroticism (Nscore) has a modest positive association, while Conscientiousness (Cscore) is negatively related to cannabis use.

### Cannabis Usage Linear Regression Model: Diagnostic Analysis

```{r lr9, echo=FALSE, cache=TRUE, fig.width=6, fig.height=4.5}
#---------------------------------------------------------------
# Diagnostic Plots
#---------------------------------------------------------------

# Function to create diagnostic plots with enhanced aesthetics
create_diagnostic_plots <- function(model, title, color_scheme = "blue") {
  # Extract residuals data
  model_data <- augment(model)
  
  # Define color palette
  if (color_scheme == "blue") {
    point_color <- "#3182bd"
    line_color <- "#08519c"
    reference_color <- "#e41a1c"
  } else if (color_scheme == "green") {
    point_color <- "#31a354"
    line_color <- "#006d2c"
    reference_color <- "#d62728"
  } else {
    point_color <- "#756bb1"
    line_color <- "#54278f"
    reference_color <- "#e41a1c"
  }
  
  # Common theme elements
  diagnostic_theme <- theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 12),
      plot.subtitle = element_text(size = 9, color = "gray50"),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 9),
      panel.grid.minor = element_blank(),
      panel.border = element_rect(color = "gray80", fill = NA, linewidth = 0.5)
    )
  
  # Residuals vs Fitted with improved aesthetics
  p1 <- ggplot(model_data, aes(x = .fitted, y = .resid)) +
    geom_point(alpha = 0.6, color = point_color, size = 1.5) +
    geom_hline(yintercept = 0, linetype = "dashed", color = reference_color, 
               linewidth = 0.7) +
    geom_smooth(se = TRUE, color = line_color, fill = alpha(line_color, 0.2), 
                method = "loess", message = FALSE, warning = FALSE) +
    labs(title = "Residuals vs Fitted",
         subtitle = "Should show random scatter around the zero line",
         x = "Fitted values",
         y = "Residuals") +
    diagnostic_theme
  
  # Normal Q-Q plot with improved aesthetics
  p2 <- ggplot(model_data, aes(sample = .resid)) +
    stat_qq(color = point_color, size = 1.5, alpha = 0.6) +
    stat_qq_line(color = reference_color, linewidth = 0.7) +
    labs(title = "Normal Q-Q Plot",
         subtitle = "Points should follow the diagonal line",
         x = "Theoretical Quantiles",
         y = "Sample Quantiles") +
    diagnostic_theme
  
  # Scale-Location plot with improved aesthetics
  p3 <- ggplot(model_data, aes(x = .fitted, y = sqrt(abs(.resid)))) +
    geom_point(alpha = 0.6, color = point_color, size = 1.5) +
    geom_smooth(se = TRUE, color = line_color, fill = alpha(line_color, 0.2), 
                method = "loess", message = FALSE, warning = FALSE) +
    labs(title = "Scale-Location",
         subtitle = "Should show homogeneous variance",
         x = "Fitted values",
         y = "sqrt|Standardized Residuals|") +
    diagnostic_theme
  
  # Residuals vs Leverage with improved aesthetics
  p4 <- ggplot(model_data, aes(x = .hat, y = .resid)) +
    geom_point(alpha = 0.6, color = point_color, size = 1.5) +
    geom_smooth(se = TRUE, color = line_color, fill = alpha(line_color, 0.2), 
                method = "loess", message = FALSE, warning = FALSE) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
    stat_contour(aes(z = .cooksd), breaks = c(0.5, 1), color = "red", 
                 linetype = "dashed", na.rm = TRUE) +
    labs(title = "Residuals vs Leverage",
         subtitle = "Identifies influential cases",
         x = "Leverage",
         y = "Standardized Residuals") +
    diagnostic_theme
  
  # Combine plots with better layout
  title_grob <- grid::textGrob(
    title, 
    gp = grid::gpar(fontsize = 16, fontface = "bold"),
    just = "center"
  )
  subtitle_grob <- grid::textGrob(
    "Diagnostic Plots for Linear Regression Model", 
    gp = grid::gpar(fontsize = 12, col = "gray30"),
    just = "center"
  )
  
  # Arrange the title, subtitle, and plots
  combined_plot <- gridExtra::grid.arrange(
    gridExtra::arrangeGrob(title_grob, subtitle_grob, heights = c(1, 0.5), ncol = 1),
    gridExtra::arrangeGrob(p1, p2, p3, p4, ncol = 2),
    heights = c(1, 10)
  )
  
  return(combined_plot)
}

# If we have diagnostic plots for Cannabis model
if (exists("cannabis_model") && !is.null(cannabis_model)) {
  cannabis_diagnostics <- create_diagnostic_plots(cannabis_model, "Cannabis Usage Model Diagnostics")
}
```

**Residuals vs Fitted Plot Analysis** This plot for the Cannabis model shows some systematic patterning in residuals, rather than random scatter, suggesting potential non-linear relationships or uncaptured data structures that the linear model fails to address. This might indicate a need for transformations or interaction terms.

**Normal Q-Q Plot Analysis** The Q-Q plot indicates reasonable conformity of residuals to a normal distribution in the central region, but with notable deviations at the extremes, suggesting heavier tails than normal. This implies the model might be less reliable for predicting very high or very low cannabis usage levels.

**Scale-Location Plot Analysis** A non-horizontal trend in this plot points to heteroscedasticity, meaning the variance of residuals changes across fitted values. This suggests that the model's precision varies depending on the predicted level of cannabis use and can affect the efficiency of estimates and validity of standard errors.

**Residuals vs Leverage Plot Analysis** This plot shows generally favorable characteristics, with most observations having moderate leverage and no extreme outliers significantly influencing the model parameters. This enhances confidence in the overall stability of the model's findings.

**Conclusion** The diagnostic analysis of the linear regression model for cannabis usage reveals some limitations. Non-random residual patterns, deviations from normality (especially in the tails), and heteroscedasticity suggest that the model does not capture all relevant data structures. While these issues should be considered when interpreting results, the model remains useful for its primary goal of identifying significant predictors and their relative importance. The diagnostics do not invalidate the substantive findings but help contextualize them and highlight areas for potential model refinement in future work.

## Generalised Linear Model with family set to Poisson (Johan Ferreira)

```{R pois1, echo=FALSE, cache=TRUE, fig.width=5, fig.height=3.5}
# Read the data
model_data <- read.csv("Data/model_data.csv")

# Remove the first index column if it exists
if(names(model_data)[1] == "X") {
  model_data <- model_data[,-1]
}
```

```{R pois2, echo=FALSE, cache=TRUE, fig.width=5, fig.height=3.5}
# Define the predictors to use in models
predictors <- c("Age", "Gender", "Education", 
                "Nscore", "Escore", "Oscore", "Ascore", "Cscore", 
                "Impulsive", "SS")

# Function to fit Poisson GLM for a specific drug
fit_poisson_glm <- function(data, drug, predictors) {
  # Create formula
  formula_str <- paste(drug, "~", paste(predictors, collapse = " + "))
  formula <- as.formula(formula_str)

  # Fit Poisson GLM
  model <- glm(formula, data = data, family = poisson(link = "log"))

  # Return model
  return(model)
}
```

```{R pois3, echo=FALSE, cache=TRUE, fig.width=5, fig.height=3.5}
# Drugs to model
drugs_for_poisson_table <- c("Cannabis", "Alcohol", "Nicotine", "Coke", "Ecstasy")

# Fit models for each drug
models <- list()
for (drug in drugs_for_poisson_table) {
  if (drug %in% names(model_data)) {
    # Ensure the response variable is numeric and non-negative for Poisson
    if(is.numeric(model_data[[drug]]) && all(model_data[[drug]] >= 0, na.rm = TRUE)) {
      models[[drug]] <- fit_poisson_glm(model_data, drug, predictors)
    } else {
      cat("Warning: Drug column", drug, "is not suitable for Poisson regression (must be numeric and non-negative). Skipping.\n")
    }
  } else {
    cat("Warning: Drug column", drug, "not found in dataset. Skipping.\n")
  }
}
# Filter out any NULL models from the list if a drug was skipped
models <- Filter(Negate(is.null), models)
# Update drugs_for_poisson_table to only include successfully modeled drugs
drugs_for_poisson_table <- names(models)
```

```{R pois4, echo=FALSE, cache=TRUE, fig.width=5, fig.height=3.5}
# Function to create a comparison table for Poisson models (similar to lr5's table)
create_poisson_comparison_table <- function(model_list, drug_names) {
  # Key variables to include (same as in predictors for consistency)
  key_vars <- c("Age", "Gender", "Education", "Nscore", "Escore",
               "Oscore", "Ascore", "Cscore", "Impulsive", "SS")

  # Create data frame for results
  result_df <- data.frame(
    Variable = c("(Intercept)", key_vars),
    stringsAsFactors = FALSE
  )

  # Add each model's coefficients
  for (drug in drug_names) {
    if (drug %in% names(model_list)) {
      model <- model_list[[drug]]
      coefs_summary <- summary(model)$coefficients

      drug_coef_text <- sapply(result_df$Variable, function(var_name) {
        if (var_name %in% rownames(coefs_summary)) {
          estimate <- coefs_summary[var_name, "Estimate"]
          return(sprintf("%.3f", round(estimate, 3)))
        } else {
          return("") 
        }
      })
      result_df[[drug]] <- drug_coef_text
    } else {
      result_df[[drug]] <- "" 
    }
  }

  # Add model metrics
  # Using LaTeX command for Chi and generic R-squared labels
  metrics_rows <- data.frame(
    Variable = c("N", "Pseudo R²", "Adjusted Pseudo R²", "Model $\\chi^2$"),
    stringsAsFactors = FALSE
  )

  for (drug in drug_names) {
    if (drug %in% names(model_list)) {
      model <- model_list[[drug]]
      n <- nobs(model)
      
      logLik_model <- as.numeric(logLik(model))
      null_model <- glm(as.formula(paste(drug, "~ 1")), 
                        data = model$model, 
                        family = poisson(link = "log"))
      logLik_null <- as.numeric(logLik(null_model))
      pseudo_r2 <- 1 - (logLik_model / logLik_null)
      
      k_predictors <- length(coef(model)) - 1 
      adj_pseudo_r2 <- 1 - ( (logLik_model - k_predictors) / logLik_null )
      
      model_chi_sq <- model$null.deviance - model$deviance

      metrics_rows[[drug]] <- c(
        as.character(n),
        sprintf("%.3f", round(pseudo_r2, 3)),
        sprintf("%.3f", round(adj_pseudo_r2, 3)),
        sprintf("%.2f", round(model_chi_sq, 2)) 
      )
    } else {
      metrics_rows[[drug]] <- rep("", 4)
    }
  }

  final_df <- rbind(result_df, metrics_rows)

  # Clean variable names for display (similar to lr5)
  var_display_names <- c(
    "(Intercept)" = "Intercept",
    "Age" = "Age",
    "Gender" = "Gender (Male=1)",
    "Education" = "Education Level",
    "Nscore" = "Neuroticism",
    "Escore" = "Extraversion",
    "Oscore" = "Openness",
    "Ascore" = "Agreeableness",
    "Cscore" = "Conscientiousness",
    "Impulsive" = "Impulsivity",
    "SS" = "Sensation Seeking",
    "N" = "N",
    "Pseudo R²" = "Pseudo R²", 
    "Adjusted Pseudo R²" = "Adjusted Pseudo R²", 
    "Model $\\chi^2$" = "Model $\\chi^2$" # LaTeX for Chi
  )
  
  # Apply display names
  final_df$Variable <- sapply(final_df$Variable, function(x) {
    if (x %in% names(var_display_names)) return(var_display_names[x])
    return(x)
  })

  # Reorder to match a specific display order
  desired_order <- c(
    "Intercept", "Age", "Gender (Male=1)", "Education Level",
    "Neuroticism", "Extraversion", "Openness", "Agreeableness",
    "Conscientiousness", "Impulsivity", "Sensation Seeking",
    "N", "Pseudo R²", "Adjusted Pseudo R²", "Model $\\chi^2$"
  )
  final_df$Variable <- factor(final_df$Variable, levels = desired_order)
  final_df <- final_df[order(final_df$Variable), ]

  return(final_df)
}
```

### Analysis of Cannabis Usage Poisson Model  

```{r pois5, echo=FALSE, cache=TRUE, fig.width=5, fig.height=3.5, results='asis'}
# Create and display the Poisson model comparison table

if (length(models) > 0 && length(drugs_for_poisson_table) > 0) {
  poisson_comparison_table_data <- create_poisson_comparison_table(
    models,
    drugs_for_poisson_table 
  )
  
  poisson_kable_table <- kable(poisson_comparison_table_data,
        format = "latex", 
        caption = "Poisson Regression Models for Drug Usage",
        align = c('l', rep('r', ncol(poisson_comparison_table_data) - 1)),
        booktabs = TRUE,
        longtable = TRUE,
        escape = FALSE) %>% 
    kable_styling(
      latex_options = c("striped", "hold_position"), 
      full_width = FALSE,
      position = "center"                             
    ) %>%
    row_spec(0, bold = TRUE) %>%                      
    column_spec(1, bold = TRUE) %>%                   
    add_header_above(c(" " = 1, "Drug Models" = ncol(poisson_comparison_table_data) - 1))
    # Footnote has been removed
  
  print(poisson_kable_table)

} else {
  cat("No Poisson models were successfully generated to display in the table.\n")
}
```

Poisson regression models revealed significant associations between personality, demographics, and the frequency of substance use. The Cannabis model likely showed the strongest explanatory power (highest Pseudo R²), with models for Coke and Ecstasy also indicating personality as key to use frequency. Key personality traits consistently predicted use frequency: Sensation Seeking (SS) and Impulsivity were strong positive predictors for substances like Cannabis, Coke, and Ecstasy, while Conscientiousness (Cscore) was a significant negative (protective) predictor across several drugs. Openness to Experience (Oscore) positively correlated with the use frequency of Cannabis and Ecstasy.

Among demographic factors, Age generally showed a negative association with use frequency, especially for illicit drugs. Being Male was often linked to higher use frequency. Model fit statistics (Pseudo R² and significant Model chi 2) confirmed that the predictors collectively explained usage frequency significantly better than chance. Overall, the Poisson models largely affirm the linear regression findings regarding predictor directions, but offer a more suitable framework for analyzing use frequency, strengthening conclusions about risk and protective factors in substance consumption patterns.

### Analysis of Personality Traits as Predictors of Cannabis Use

```{r pios6, echo=FALSE, cache=TRUE, fig.width=6, fig.height=3.5}
plot_glm_factor_importance_enhanced <- function(model, title, color_scheme = "viridis") {
  coefs_summary <- summary(model)$coefficients
  coef_df <- data.frame(
    Variable = rownames(coefs_summary)[-1],  
    Estimate = coefs_summary[-1, "Estimate"],
    StdError = coefs_summary[-1, "Std. Error"],
    PValue = coefs_summary[-1, "Pr(>|z|)"] 
  )
  
  # Add significance markers and categories
  coef_df$Significance <- ifelse(coef_df$PValue < 0.001, "p < 0.001", 
                               ifelse(coef_df$PValue < 0.01, "p < 0.01",
                                    ifelse(coef_df$PValue < 0.05, "p < 0.05", "Not significant")))
  
  # Sort by absolute value of estimate for better visualization
  coef_df <- coef_df[order(abs(coef_df$Estimate), decreasing = TRUE), ]
  
  # Keep only top 15 predictors for visualization
  if(nrow(coef_df) > 15) {
    coef_df <- coef_df[1:15, ]
  }
  
  # Clean up variable names for display using a predefined mapping
  var_display_mapping <- c(
    "Age" = "Age",
    "Gender" = "Gender (Male=1)",
    "Education" = "Education Level",
    "Nscore" = "Neuroticism",
    "Escore" = "Extraversion",
    "Oscore" = "Openness",
    "Ascore" = "Agreeableness",
    "Cscore" = "Conscientiousness",
    "Impulsive" = "Impulsivity",
    "SS" = "Sensation Seeking"
    )
  
  # Function to clean up variable names
  clean_var_names <- function(var_name) {
    if (var_name %in% names(var_display_mapping)) {
      return(var_display_mapping[var_name])
    }
    if (grepl("^Country", var_name)) {
      return(gsub("Country", "Country: ", var_name))
    }
    if (grepl("^Ethnicity", var_name)) {
      return(gsub("Ethnicity", "Ethnicity: ", var_name))
    }
    return(var_name) # Return original name if no mapping found
  }
  
  # Apply name cleaning
  coef_df$DisplayName <- sapply(coef_df$Variable, clean_var_names)
  
  # Reorder factor levels for plotting (so highest absolute estimate is at the top)
  coef_df$DisplayName <- factor(coef_df$DisplayName, levels = rev(coef_df$DisplayName))
  
  # Define significance color palette based on the chosen scheme
  if (color_scheme == "viridis") {
    sig_colors <- c("p < 0.001" = "#440154", "p < 0.01" = "#21908C", 
                    "p < 0.05" = "#5DC863", "Not significant" = "#CCCCCC")
  } else { # Default to a blue-ish scheme if not viridis
    sig_colors <- c("p < 0.001" = "#0072B2", "p < 0.01" = "#009E73", 
                    "p < 0.05" = "#56B4E9", "Not significant" = "#CCCCCC")
  }
  
  # Create the plot using ggplot2
  p <- ggplot(coef_df, aes(x = Estimate, y = DisplayName, color = Significance)) +
    geom_point(aes(size = abs(Estimate)), alpha = 0.8) +
    geom_errorbarh(aes(xmin = Estimate - 1.96 * StdError, 
                       xmax = Estimate + 1.96 * StdError), 
                   height = 0.2, alpha = 0.7) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "darkgray", linewidth = 0.7) +
    scale_color_manual(values = sig_colors) +
    scale_size_continuous(range = c(2, 6), guide = "none") +
    labs(title = title,
         x = "Effect Size",
         y = "",
         color = "Statistical\nSignificance") +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
      axis.title.x = element_text(size = 12, face = "bold"),
      axis.text.y = element_text(size = 10),
      legend.position = "top",
      legend.title = element_text(face = "bold"),
      panel.grid.minor = element_blank(),
      panel.grid.major.y = element_blank()
    )
  
  return(p)
}


if (exists("models") && "Cannabis" %in% names(models) && !is.null(models[["Cannabis"]])) {
  cannabis_poisson_model_object <- models[["Cannabis"]]
  
  # Generate and print the coefficient plot
  cannabis_poisson_coef_plot <- plot_glm_factor_importance_enhanced(
    model = cannabis_poisson_model_object, 
    title = "Predictors of Cannabis (Poisson Model)",
    color_scheme = "viridis"
  )
  
  print(cannabis_poisson_coef_plot)
  
} else {
  message("Cannabis Poisson model ('models[[\"Cannabis\"]]') not found or is NULL. \nPlease ensure it has been fitted correctly, typically in a chunk like 'pois3'.")
}

```

The Poisson regression model reveals key factors influencing cannabis usage frequency. Sensation Seeking is the most potent positive predictor (p < 0.001), with higher Openness, Impulsivity, Neuroticism (all p < 0.001), and being male (p < 0.001) also increasing expected use. Conversely, older Age and higher Conscientiousness (both p < 0.001) are strong negative predictors. Increased Education, Agreeableness (both p < 0.001), and Extraversion (p < 0.05) are associated with lower frequency. These findings detail the impact of personality and demographics on the regularity of cannabis use, highlighting Sensation Seeking, Age, Openness, and Conscientiousness as particularly influential.

**Comparative Analysis between the Linear and Poisson Models**

Both models analyze personality/demographic factors affecting cannabis use but differ in their approach—the linear model looks at general use levels, while the Poisson model analyzes use frequency.

Both models consistently identify several predictors with similar direction and high significance:  
- Sensation Seeking (SS): The strongest positive predictor (p < 0.001).  
- Age: A strong negative predictor (p < 0.001).  
- Openness (Oscore): A significant positive predictor (p < 0.001).  
- Conscientiousness (Cscore): A negative predictor (Poisson model specifies p < 0.001 for frequency).  
- Neuroticism (Nscore): Shows a positive association (Poisson model finds p < 0.001 with frequency).  

Key differences arise from the Poisson model's specificity for frequency, leading to a broader set of identified significant predictors. The Poisson model additionally highlights as highly significant for usage frequency:  
- Impulsivity: Positive predictor (p < 0.001).  
- Gender (Male=1): Positive predictor (p < 0.001).  
- Education Level: Negative predictor (p < 0.001).  
- Agreeableness (Ascore): Negative predictor (p < 0.001).  
- Extraversion (Escore): Negative predictor (p < 0.05).  

These differences likely stem from the linear model assessing general use levels (as a continuous variable), whereas the Poisson model, designed for count data (frequency), can be more sensitive to factors influencing how often cannabis is used. Consequently, the Poisson model's descriptions also provide more explicit high significance levels (e.g., p < 0.001) for traits like Conscientiousness and Neuroticism compared to the linear model's more general statements.

### Analysis of Poisson Models with Interaction Terms for Cannabis Usage

```{r pois_multi_inter, echo=FALSE, cache=TRUE, results='asis', fig.width=5, fig.height=4}
# Define the outcome variable
outcome_variable <- "Cannabis"

# Define all potential main predictors
all_main_predictors <- c("Age", "Gender", "Education", 
                         "Nscore", "Escore", "Oscore", "Ascore", "Cscore", 
                         "Impulsive", "SS")

# Define the list of interaction pairs (var1, var2)
interaction_pairs <- list(
  c("Age", "Education"),
  c("Gender", "SS"),
  c("Age", "SS"),
  c("Education", "Cscore"),
  c("Oscore", "SS"),
  c("Cscore", "Impulsive"),
  c("Age", "Oscore"),
  c("Gender", "Impulsive")
)

# Initialize a list to store results from each model
results_list_updated <- list()

# Loop through each interaction pair
for (i in 1:length(interaction_pairs)) {
  var1 <- interaction_pairs[[i]][1]
  var2 <- interaction_pairs[[i]][2]
  
  # Determine other main effects to include in the model
  other_main_effects <- setdiff(all_main_predictors, c(var1, var2))
  
  # Construct the formula string
  formula_str <- paste0(outcome_variable, " ~ ", var1, " * ", var2)
  if (length(other_main_effects) > 0) {
    formula_str <- paste0(formula_str, " + ", paste(other_main_effects, collapse = " + "))
  }
  
  current_formula <- as.formula(formula_str)
  
  # Fit the Poisson GLM
  model <- glm(current_formula, data = model_data, family = poisson(link = "log"))
  
  # Extract model summary and coefficients
  model_summary_tidy <- broom::tidy(model)
  
  # Find the interaction term to get its coefficient and p-value
  interaction_term_name1 <- paste0(var1, ":", var2)
  interaction_term_name2 <- paste0(var2, ":", var1) 
  
  interaction_coef_row <- model_summary_tidy[model_summary_tidy$term == interaction_term_name1, ]
  if (nrow(interaction_coef_row) == 0) {
    interaction_coef_row <- model_summary_tidy[model_summary_tidy$term == interaction_term_name2, ]
  }
  
  interaction_coefficient <- NA
  interaction_p_value <- NA

  if (nrow(interaction_coef_row) == 1) {
    interaction_coefficient <- interaction_coef_row$estimate
    interaction_p_value <- interaction_coef_row$p.value
  }

  # Calculate McFadden's Pseudo R-squared
  logLik_model <- as.numeric(logLik(model))
  null_model_data <- model$model 
  null_model <- glm(as.formula(paste(outcome_variable, "~ 1")), 
                    data = null_model_data, 
                    family = poisson(link = "log"))
  logLik_null <- as.numeric(logLik(null_model))
  pseudo_r2 <- 1 - (logLik_model / logLik_null)
  
  # Store results (Interaction_Term column removed)
  results_list_updated[[i]] <- data.frame(
    Model_Interaction = paste0(var1, " * ", var2),
    Interaction_Coefficient = interaction_coefficient,
    Interaction_P_Value = interaction_p_value,
    AIC = AIC(model),
    BIC = BIC(model),
    Pseudo_R2 = pseudo_r2,
    stringsAsFactors = FALSE
  )
}

# Combine all results into a single data frame
final_results_table_updated <- do.call(rbind, results_list_updated)

# Display the table using kable with LaTeX styling
kable(final_results_table_updated,
      format = "latex", 
      caption = "Comparison of Poisson Models with Different Interaction Terms (Outcome: Cannabis)",
      digits = 3, 
      booktabs = TRUE,
      linesep = "", 
      col.names = c("Model (A * B)", "Coef.", "P-value", "AIC", "BIC", "Pseudo R²")) %>% # Shortened some col names
  kable_styling(latex_options = c("striped", "hold_position"), 
                full_width = FALSE,
                position = "center") %>%
  column_spec(1, bold = TRUE, width = "8em") %>% # Reduced width for Col 1, try adjusting this
  column_spec(2, width = "5em") %>% # Width for Coef.
  column_spec(3, width = "5em") %>% # Width for P-value
  column_spec(4, width = "6em") %>% # Width for AIC
  column_spec(5, width = "6em") %>% # Width for BIC
  column_spec(6, width = "6em") %>% # Width for Pseudo R²
  row_spec(0, bold = TRUE)
```  

To explore more complex relationships influencing cannabis usage, eight Poisson regression models were fitted, each incorporating a distinct two-way interaction term. Several interactions significantly moderated the relationship between predictors and the frequency of cannabis use:

- The Age:SS interaction (p < 0.001) suggested Sensation Seeking's effect on cannabis use intensifies with age, or the typical age-related decline in use is less pronounced for individuals with higher Sensation Seeking scores.
- The Age:Oscore interaction (p < 0.001) indicated Openness's positive association with cannabis usage is amplified in older individuals.
- Significant negative interactions for Gender:SS and Gender:Impulsive (both p < 0.001 with negative coefficients) suggested that the positive effects of Sensation Seeking and Impulsivity on cannabis usage are less pronounced for males (assuming Male=1).
- The Oscore:SS interaction (p < 0.001 with a negative coefficient) implied their combined positive effect on usage is less than additive; for example, high Sensation Seeking's impact might be dampened for those also high in Openness.
- Other interactions, such as Age:Education, were not statistically significant (p > 0.05), while Cscore:Impulsive showed borderline significance (p = 0.068).

In terms of overall model fit, the Pseudo R² values (approximately 0.162 to 0.168) showed modest improvements over models with only main effects. Comparing AIC and BIC values, the model incorporating the Age * Oscore interaction exhibited the lowest AIC and BIC, suggesting it offered the best balance of model fit and parsimony. These findings highlight that the influence of personality traits and demographic factors on cannabis usage can be conditional, providing a more nuanced understanding of drug consumption.

```{r pois9, echo=FALSE, cache=TRUE, fig.width=6, fig.height=4.5}
# Define the predictors to use in models
predictors <- c("Age", "Gender", "Education", 
                "Nscore", "Escore", "Oscore", "Ascore", "Cscore", 
                "Impulsive", "SS")

# Formula for Cannabis
cannabis_formula_str <- paste("Cannabis ~", paste(predictors, collapse = " + "))
cannabis_formula <- as.formula(cannabis_formula_str)

# Fit Poisson GLM for Cannabis
if("Cannabis" %in% names(model_data) && 
   is.numeric(model_data$Cannabis) && 
   all(model_data$Cannabis >= 0, na.rm = TRUE) &&
   all(model_data$Cannabis == floor(model_data$Cannabis), na.rm = TRUE)) {
  
  cannabis_poisson_model <- glm(cannabis_formula, data = model_data, family = poisson(link = "log"))
  message("Cannabis Poisson model fitted successfully.")
  
} else {
  stop("Cannabis column is not suitable for Poisson regression or not found. It must be numeric, non-negative, and contain integers.")
}


# Define the Diagnostic Plot Function
create_diagnostic_plots_glm <- function(model, title, color_scheme = "blue") {
  model_data_aug <- broom::augment(model, type.predict = "response", type.residuals = "pearson")

  # Define color palette
  if (color_scheme == "blue") {
    point_color <- "#3182bd"
    line_color <- "#08519c"
    reference_color <- "#e41a1c"
  } else if (color_scheme == "green") {
    point_color <- "#31a354"
    line_color <- "#006d2c"
    reference_color <- "#d62728"
  } else { # Default purple-ish
    point_color <- "#756bb1"
    line_color <- "#54278f"
    reference_color <- "#e41a1c"
  }
  
  # Common theme elements
  diagnostic_theme <- theme_minimal(base_size = 9) + 
    theme(
      plot.title = element_text(face = "bold", size = rel(1.2)),
      plot.subtitle = element_text(size = rel(0.9), color = "gray50"),
      axis.title = element_text(size = rel(1)),
      axis.text = element_text(size = rel(0.9)),
      panel.grid.minor = element_blank(),
      panel.border = element_rect(color = "gray80", fill = NA, linewidth = 0.5)
    )
  
  # 1. Residuals vs Fitted.
  p1 <- ggplot(model_data_aug, aes(x = .fitted, y = .std.resid)) + 
    geom_point(alpha = 0.6, color = point_color, size = 1.5) +
    geom_hline(yintercept = 0, linetype = "dashed", color = reference_color, linewidth = 0.7) +
    geom_smooth(se = TRUE, color = line_color, fill = alpha(line_color, 0.2), 
                method = "loess", formula = 'y ~ x', na.rm = TRUE, linewidth=0.5) +
    labs(title = "Residuals vs Fitted",
         subtitle = "Std. Pearson Residuals. Check for patterns & non-constant variance.",
         x = "Fitted values (response scale)",
         y = "Standardized Pearson Residuals") +
    diagnostic_theme
  
  # 2. Normal Q-Q plot of Standardized Pearson Residuals
  p2 <- ggplot(model_data_aug, aes(sample = .std.resid)) +
    stat_qq(color = point_color, size = 1.5, alpha = 0.6) +
    stat_qq_line(color = reference_color, linewidth = 0.7) +
    labs(title = "Normal Q-Q Plot",
         subtitle = "Std. Pearson Residuals. Check for normality (less critical for GLM).",
         x = "Theoretical Quantiles",
         y = "Sample Quantiles (Std. Pearson Res.)") +
    diagnostic_theme
  
  # 3. Scale-Location plot
  model_data_aug$.sqrt.abs.std.resid <- sqrt(abs(model_data_aug$.std.resid))
  p3 <- ggplot(model_data_aug, aes(x = .fitted, y = .sqrt.abs.std.resid)) +
    geom_point(alpha = 0.6, color = point_color, size = 1.5) +
    geom_smooth(se = TRUE, color = line_color, fill = alpha(line_color, 0.2), 
                method = "loess", formula = 'y ~ x', na.rm = TRUE, linewidth=0.5) + 
    labs(title = "Scale-Location",
         subtitle = "sqrt(|Std. Pearson Res.|). Check for homoscedasticity.",
         x = "Fitted values (response scale)",
         y = "sqrt(|Standardized Pearson Residuals|)") +
    diagnostic_theme
  
  # 4. Residuals vs Leverage 
  p4 <- ggplot(model_data_aug, aes(x = .hat, y = .std.resid)) +
    geom_point(alpha = 0.6, color = point_color, size = 1.5) +
    geom_smooth(se = TRUE, color = line_color, fill = alpha(line_color, 0.2), 
                method = "loess", formula = 'y ~ x', na.rm = TRUE, linewidth=0.5) + 
    geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
    labs(title = "Residuals vs Leverage",
         subtitle = "Std. Pearson Res. vs Leverage. Identifies influential cases.",
         x = "Leverage (.hat)",
         y = "Standardized Pearson Residuals") +
    diagnostic_theme
  main_title_grob <- grid::textGrob(
    title, 
    gp = grid::gpar(fontsize = rel(1.5) * 9, fontface = "bold"), 
    just = "center"
  )
   plot_grid <- gridExtra::arrangeGrob(p1, p2, p3, p4, ncol = 2)
   combined_plot <- gridExtra::grid.arrange(main_title_grob, plot_grid, heights = c(1,10), ncol=1)
  return(combined_plot)
}

# --- Generate and print diagnostic plots for the Cannabis Poisson model ---
if (exists("cannabis_poisson_model") && !is.null(cannabis_poisson_model)) {
  cannabis_poisson_diagnostics <- create_diagnostic_plots_glm(
    cannabis_poisson_model,
    "Cannabis Usage Poisson Model Diagnostics"
  ) 

} else {
  message("Cannabis Poisson model object not found or is NULL. Diagnostics cannot be generated.")
}
```

**Residuals vs Fitted Plot Analysis** The Residuals vs Fitted plot for the Cannabis Poisson model likely reveals some systematic patterning and a fanning out of residuals, indicative of overdispersion where the variance increases more than the mean. This suggests the standard Poisson assumption may not fully hold, potentially requiring model adjustments like Negative Binomial regression or inclusion of further interaction terms.

**Normal Q-Q Plot of Standardized Pearson Residuals Analysis** The Normal Q-Q plot of standardized Pearson residuals likely shows deviations from the diagonal, particularly at the tails, suggesting that the distribution of residuals is not perfectly normal. While less critical for Poisson models than for linear regression, this can indicate the model might struggle with predicting very frequent or very infrequent cannabis usage counts accurately.

**Scale-Location Plot Analysis** The Scale-Location plot likely exhibits an upward trend in the LOESS smoother, indicating that the variance of the residuals increases with the fitted mean values more than the Poisson model assumes. This is a strong sign of overdispersion, suggesting the model's precision varies and standard errors might be underestimated.

**Residuals vs Leverage Plot Analysis** The Residuals vs Leverage plot for the Cannabis Poisson model likely shows most observations with low to moderate leverage, though a few points might stand out with higher leverage or larger residuals. While the bulk of the data may not unduly influence parameters, any identified influential points would warrant closer inspection.

**Conclusion** The diagnostic analysis of the Cannabis Poisson model highlights probable overdispersion and some non-random patterns in residuals, suggesting the basic Poisson structure may not fully capture the data's complexity. These issues, particularly overdispersion, can affect standard errors and p-values, indicating that while predictor directions might be informative, model refinements (like Negative Binomial regression, as explored in the Rmd) are crucial for more accurate inference and robust conclusions.

## Generalised Linear Model with family set to Binomial (Nhat Bui)

```{r glmbi_model5, echo=FALSE, cache=TRUE, results ='hide'}
# Fit the model 

model <- glm(cnb_use ~ Nscore + Escore + Oscore + Ascore + Cscore, family = binomial, data = df_cnb)
summary(model)
```
```{r glmbi_model5_kable, echo=FALSE, cache=TRUE}
cnb_model <- broom::tidy(model) %>%
  mutate(
    raw_p = p.value,
    p.value = round(p.value, 3),
    p.value = ifelse(p.value < 0.001, sprintf("%.2e", raw_p), p.value),
    OR = round(exp(estimate), 2),
    lower_CI = round(exp(estimate - 1.96 * std.error), 2),
    upper_CI = round(exp(estimate + 1.96 * std.error), 2),
        term     = recode(term,
               `(Intercept)` = "Intc.",
               Nscore        = "Neuroticism",
               Escore        = "Extraversion",
               Oscore        = "Openness",
               Ascore        = "Agreeableness",
               Cscore        = "Conscientiousness"
             )
  ) %>%
  select(term, estimate, OR, lower_CI, upper_CI, p.value)

kable(cnb_model, 
      col.names = c("Term", "Estimate", "OR", "Lower 95%", "Upper 95%", "p-value"),
      digits = c( NA, 3, 2, 2, 2, NA),
      caption = "Logistic Regression (Binomial GLM) Results") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width        = FALSE,
    position          = "center",
    font_size         = 12
  ) %>%
  row_spec(0, bold = TRUE) %>%        
  column_spec(1, width = "4cm") %>%   
  column_spec(2:5, width = "2.5cm") %>%
  column_spec(6, width = "3cm")      
```

People who score high in Openness are more than twice as likely to have ever tried cannabis (OR = 2.51; 95 % CI 2.18–2.89; p < 0.001). In plain terms, each one‐point increase in openness roughly doubles someone’s odds of experimentation. On the flip side, those higher in Conscientiousness are about half as likely to try it (OR = 0.57; 95 % CI 0.49–0.66; p < 0.001). That means a one‐point bump in conscientiousness cuts the odds of ever using cannabis by roughly 43 %. When you combine these two traits, someone who is extremely curious but also extremely disciplined might face an internal tug‐of‐war—yet the numbers show that conscientiousness carries a similarly strong protective effect as openness carries a strong risk factor.

Extraversion shows a significant protective effect as well (OR = 0.83; 95 % CI 0.71–0.96; p = 0.012). In other words, being more outgoing is linked with a roughly 17 % lower odds of having tried cannabis. That counters to the idea that extroverts would be more exposed to peer‐driven experimentation. Instead, it suggests extroverts may socialize in sports teams, clubs, family events—that do not revolve around drug use.

Meanwhile, Agreeableness also reduces the odds of having tried cannabis (OR = 0.74; 95 % CI 0.65–0.85; p = 0.000006). A one‐point rise in agreeableness leads to about a 26 % lower chance of ever using. This implies that more cooperative, trustful, and conflict‐averse people tend to avoid experimentation. Conversely, Neuroticism does not show a significant effect here (OR = 0.92; 95 % CI 0.80–1.07; p = 0.284), indicating that anxiety or emotional volatility neither attracts people toward their first try.

Putting these results together, it becomes clear that Openness and Conscientiousness are the dominant forces: curious, open‐minded individuals are most at risk, while disciplined, rule‐oriented people are much less likely to experiment. Extraversion and agreeableness offer smaller but still meaningful protection of drugs, while neuroticism appears unrelated in this sample. 

## Generalised Additive Model (Nhat Bui)

```{r gam_eda_plot_edu, echo=FALSE, cache=TRUE, fig.width=5, fig.height=2.5}
df_cnb <- df_cnb %>%
  mutate(
    cnb_past_year = if_else(Cannabis >= 3, 1, 0)
  )
ggplot(df_cnb, aes(x = Education,
                   y = cnb_past_year,
                   group = 1)) +          
  geom_point(alpha = 0.5) +
  stat_smooth(
    method      = "gam",
    formula     = y ~ s(x, k = 4),     
    method.args = list(family = binomial),  
    se          = TRUE
  ) +
  labs(
    title = "Past-Year Cannabis Use vs. Education (GAM, k = 4)",
    x     = "Education",
    y     = "Past-Year Cannabis Use (0/1)"
  ) +
  theme_minimal(base_size = 8)
```

This GAM‐derived curve describes how the probability of past-year cannabis use (vertical axis) changes as education rises from level 1 (“Not Provided/left before 16”) through level 10 (“Doctorate”).

At the lowest education levels (1–2), estimated use probability starts at around 40–45%. As education levels switch into level 3 - 5 (left school at 16, 17, 18 respectively), the probability climbs steadily, reaching a peak near 80% at level 5 (left school at 18). Beyond that peak, the probability falls off sharply—by the professional certificate and bachelor’s levels (6–7) it has dropped to roughly 50–60%, and by master’s level (8) it’s down near 30–35%. Finally, the curve flattens out (and even nudges upward a bit) at the doctorate level (9–10), but the wide confidence ribbon there indicates greater uncertainty due to sparse observations.

The gray band is the 95% confidence interval around the estimated probability. It is narrowest in the middle education bands (levels 3–7), where most of the data lies, so those estimates are quite precise. At the extremes (very low and very high education), the ribbon fans out, signaling that fewer respondents occupy those categories and thus our estimates are less certain.

Taken together, this non-linear relationship shows that cannabis use probability does not simply rise or fall with education. Instead, it increases sharply through those that left school at 16, 17, 18 reflecting experimentation during teenage age and then declines among individuals with higher degrees, suggesting that the highest educational positions are associated with lower recent use.

```{r gam_eda_plot_age, echo=FALSE, cache=TRUE, fig.width=5, fig.height=2.5}
ggplot(df_cnb, aes(x = Age,
                   y = cnb_past_year,
                   group = 1)) +          
  geom_point(alpha = 0.5) +
  stat_smooth(
    method      = "gam",
    formula     = y ~ s(x, k = 3),     
    method.args = list(family = binomial),  
    se          = TRUE
  ) +
  labs(
    title = "Past-Year Cannabis Use vs. Age (GAM, k = 3)",
    x     = "Age",
    y     = "Past-Year Cannabis Use (0/1)"
  ) +
  theme_minimal(base_size = 8)
```

The GAM‐smoothed curve reveals a clear, non‐linear decline in the probability of past‐year cannabis use as people age. At the youngest age category (18–24), use is highest—around 80–85%. From there, the curve drops steeply through the 25–34 and 35–44 brackets, reaching a nadir of roughly 20–25% by middle adulthood. This matches the expected pattern that cannabis experimentation and regular use peak in early adulthood and then fall off sharply.

Beyond middle age, the decline slows and even reverses slightly: in the 55–64 and 65+ groups the estimated probability edges back up toward 30%. The widening gray confidence band in those older bins reflects smaller sample sizes and greater uncertainty, but the gentle uptick suggests that a non‐negligible minority of older adults continue to report recent use.

Because we set k = 3, the model captures just the broad “high-early, steep-decline, slight rebound” pattern without overfitting. The narrow confidence interval among younger ages shows high precision where data are plentiful, while the broader ribbon at the extremes reminds us to be cautious in interpreting the very high and very low age categories.

```{r gam_eda_plot_age_edu3, echo=FALSE, cache=TRUE,fig.width=6, fig.height=4, dpi=125}
education_levels <- c(
  "Not Provided",
  "Left school before 16",
  "Left school at 16",
  "Left school at 17",
  "Left school at 18",
  "College/University student",
  "Professional certificate/diploma",
  "University degree",
  "Masters degree",
  "Doctorate degree"
)
df_cnb <- df_cnb %>%
  mutate(
    Education = factor(
      Education,
      levels = 1:10,
      labels = education_levels
    )
  )
ggplot(df_cnb, 
       aes(x = Age, 
           y = cnb_past_year)) +   
  geom_point(alpha = 0.3) +
  stat_smooth(
    method      = "gam",
    formula     = y ~ s(x, k = 3),
    method.args = list(family = binomial),
    se          = TRUE
  ) +
  facet_wrap(~ Education, ncol = 3) +
  labs(
    title = "Past-Year Cannabis Use vs. Age, by Education Level",
    x     = "Age",
    y     = "Probability of Past-Year Use"
  ) +
  theme_minimal(base_size = 10)
```

The “less‐educated” group (e.g. “Left before 16,” “Left at 17,” “Left at 18,” “Professional certificate”) all start with extremely high probabilities of use when respondents are young, and their curves decline steeply. By midlife, those groups still often have somewhat higher past‐year use than the more‐educated strata. Whereas, the highest‐education respondent group (“University degree,” “Masters,” “Doctorate”) start at a lower baseline in the youngest age bracket, decline more gradually, and by the oldest ages are clustered down near 10–25%. n almost every panel, the highest probability occurs in the youngest age bin (18–24), reflecting that early adulthood is when use is most common. For example, those who “left school at 16” or are current “College/University students” exhibit peaks around 90 – 95% in that age group, whereas “Master’s degree” or “Doctorate degree” holders start at roughly 50–65%. As age increases from the early-20s toward the mid-40s, all panels show a steep drop

The one outlier in shape is “College/University student.” That group has a very high probability at the youngest (freshman/first‐year) ages, dips in the middle (around 35-40), then rebounds at older ages. Almost every other “education” stratum shows a decline.

The gray ribbons around each blue line are the 95% confidence intervals for the estimated probabilities. Some are narrowest in the middle of the age range and some are narrowest at the 18-24 age bin, depending on how many respondents fall into each category. The wider ribbons in the oldest age bins reflect fewer observations, making those estimates less certain.

Overall, this GAM analysis shows that education level significantly modifies the age-use curve for past-year cannabis use. Lower education levels are associated with higher use probabilities at younger ages, while higher education levels tend to delay initiation and reduce escalation of use as individuals age.

```{r gam_fit_summary, echo=FALSE, cache=TRUE}
set.seed(123)
gam.1 <- gam(
  cnb_past_year ~ 
    Education + 
    s(Age, by = Education, k = 5),
  family = binomial(link = "logit"),
  data   = df_cnb,
  method = "REML"
)

sum_gam1 <- summary(gam.1)

param_df <- as.data.frame(sum_gam1$p.table) %>%
  rownames_to_column(var = "Term") %>%
  rename(
    Estimate   = Estimate,
    Std_Error  = `Std. Error`,
    z_value    = `z value`,
    p_value    = `Pr(>|z|)`
  )

kable(
  param_df,
  caption = "Parametric Coefficients (gam.1)",
  digits  = c(0, 4, 4, 4, 4)
)

smooth_df <- as.data.frame(sum_gam1$s.table) %>%
  rownames_to_column(var = "Smooth_Term") %>%
  rename(
    edf        = edf,
    Ref_df     = Ref.df,
    Chi_sq     = Chi.sq,
    p_value_s  = `p-value`
  )

cat("\n\n")  # blank line between tables

kable(
  smooth_df,
  caption = "Approximate Significance of Smooth Terms (gam.1)",
  digits  = c(0, 3, 3, 4, 4)
)
```

The “Parametric coefficients” table shows one row for the intercept (the reference category, here “Not Provided”) and one row for each of the other education levels. The intercept row can be seen as “the starting probability of past‐year use for the ‘Not Provided’ group”, and other row tells how much higher or lower that starting probability is for each education level compared to “Not Provided.”

(Intercept) = 0.3230 (p = 0.215)
For the “Not Provided” group, the model estimates a baseline probability of about 58% (since exp(0.3230)/(1 + exp(0.3230)) = 0.58005). p = 0.215 is not significant.

Left school before 16: +1.289 (p = 0.084)
Compared to “Not Provided,” those who left school before age 16 start with a probability roughly 23 points higher—around 81% instead of 58%. The p‐value of 0.084 is just above the usual threshold of 0.05, so this is a somewhat weak signal. There is some indication that early dropouts have a higher starting chance of past‐year use, but it isn’t quite strong enough to be certain.

Left school at 17: +0.526 (p = 0.332)
This group’s baseline probability is about 12 points higher than “Not Provided” (around 70% instead of 58%), but because p = 0.332 is not significant, we cannot confidently say they truly differ from the reference.

Left school at 18: +0.028 (p = 0.941)
Essentially no difference from “Not Provided” (only a 1–2 point bump to around 59%), and p = 0.941 confirms there is no evidence of a real shift.

College/University student: +0.704 (p = 0.0148)
Students start with about an 18‐point higher probability than “Not Provided” (around 76% vs. 58%), and p = 0.0148 is below 0.05. In other words, being a current student is significantly associated with a higher baseline chance of past‐year use.

Professional certificate/diploma: –0.0003 (p = 0.999)
There is effectively no change in starting probability (stays around 58%), and p close to 1 shows no difference from the reference.

University degree: –0.578 (p = 0.0379)
University graduates begin with a probability about 13 points lower than “Not Provided” (around 45% vs. 58%). Because p = 0.0379 is below 0.05, this lower baseline is statistically significant.

Masters degree: –1.069 (p = 0.00026)
Master’s holders start with about a 27‐point lower probability at baseline (roughly 31% instead of 58%). The p‐value is very small, so this is a highly significant finding: master’s graduates are much less likely to report past‐year use at the reference age.

Doctorate degree: –0.130 (p = 0.828)
Doctorate holders show only a slight drop (about 3 points lower, or ~55% vs. 58%), and p = 0.828 indicates no significant difference from “Not Provided.”

In summary, at the initial age (where the smooth hasn’t yet adjusted upward or downward), college/university students have a significantly higher starting chance of having used cannabis in the past year; university and master’s graduates have significantly lower starting chances; and the other categories do not show clear differences compared to the “Not Provided” group.

Across nearly all education levels—except for doctorate holders—age plays a statistically significant role in predicting past-year cannabis use, but the nature of that role varies. Some groups (“Not Provided,” “Left school before 16,” and “Master’s degree”) show a simple, linear decline (edf close to 1, p < 0.01), whereas mid-education categories (“Left school at 18,” “College/University student,” “Professional certificate/diploma,” and “University degree”) display pronounced curved patterns (edf roughly 1.9–2.9, p < 0.001), peaking in early adulthood before falling. The standout finding is that doctorate holders alone show no significant age effect (edf close to 3, p = 0.3427), implying their probability of past-year use remains flat across all age bins.

It’s clear that schooling changes both where people start and how their cannabis use changes as they get older. For example, among 18–24 year‐olds, college and university students stand out as the most likely to report past‐year use, while those with bachelor’s or master’s degrees are far less likely. By contrast, early school leavers (especially those who left before 16) begin with a moderately high chance of having used, but this drops off steadily.

As people move into their late 20s and beyond, almost every education group demosntrates a real decline in use, except for doctorate holders, whose already‐low probability stays nearly flat across all age bins. But the way that drop happens is not the same for everyone: some groups (like master’s graduates or those without any schooling info) simply decline in a straight line, while others (like those who left school at 18, certificate holders, or current students) have a “hump” in their late teens or early 20s before their use tails off. In short, higher levels of education not only lower someone’s starting odds of cannabis use but also shape a different, whereas people with mid level certificates or degrees tend to be most prone in early adulthood before dropping sharply.

## Neural Network Modeling (Thilo Holstein)

Cannabis users often represent a critical group for studying patterns of progression to other drug use due to both social and biological factors. Research indicates that Cannabis use can act as a gateway, increasing the probability of trying other substances such as LSD, Ecstasy, or Cocaine. However, this progression is neither uniform nor deterministic; individual personality traits and demographic factors play significant roles in influencing this behavior.

The core idea behind the ANN modeling approach is to identify which characteristics most strongly predict whether a Cannabis user will likely engage in subsequent use of other illicit substances, for instance LSD. Drug use data were binarized to indicate recent use (within the past year), continuous predictors (personality traits and age) were standardized via z-score normalization to ensure balanced model training, while categorical variables (gender, education) were numerically encoded.

Personality traits like impulsiveness and sensation seeking are strong predictors of risk-taking and substance use. Impulsive individuals tend to experiment spontaneously, while sensation seekers pursue novel experiences, including illicit drugs. Traits such as conscientiousness and neuroticism influence susceptibility to progressing from Cannabis to other substances. Demographics – age, gender, and education – reflect social and developmental contexts affecting drug use patterns through exposure, peer influence, and life priorities.

To investigate the risk of progressing from cannabis use to other substances, we leveraged a multi-output Artificial Neural Network to predict the probability of recent LSD, Ecstasy, and Cocaine use among cannabis consumers. The ANN was trained on scaled personality traits and demographic variables, capturing complex, nonlinear relationships.

As a first step, the model was trained on a three-layer feedforward network on an 80/20 stratified split to balance complexity and prevent overfitting, using a classification loss with a strict convergence threshold and sufficient training steps.

```{r data, echo=FALSE}
# Load your data
data <- read.csv("Data/model_data.csv")
```

```{r model, echo=FALSE, cache=TRUE}
# Convert key drugs to binary (used in last year or more recently = 1, else 0)
data <- data %>%
  mutate(
    LSD_bin       = as.integer(LSD     %in% c(3, 4, 5, 6)),
    Ecstasy_bin   = as.integer(Ecstasy %in% c(3, 4, 5, 6)),
    Coke_bin      = as.integer(Coke    %in% c(3, 4, 5, 6)),
    Cannabis_user = Cannabis %in% c(3, 4, 5, 6)
  ) %>%
  filter(Cannabis_user)  # Focus only on Cannabis users

# Scale predictors and create final dataset
data_scaled <- data %>%
  mutate(across(c(Nscore, Escore, Oscore, Ascore, Cscore, Impulsive, SS, Age), scale)) %>%
  mutate(
    Gender    = as.numeric(Gender),
    Education = as.numeric(Education)
  ) %>%
  dplyr::select(
    Nscore, Escore, Oscore, Ascore, Cscore, Impulsive, SS, Age,
    Gender, Education,
    LSD_bin, Ecstasy_bin, Coke_bin
  )

# Define formula
formula <- LSD_bin + Ecstasy_bin + Coke_bin ~ 
  Nscore + Escore + Oscore + Ascore + Cscore + Impulsive + SS + 
  Age + Gender + Education

# Train-test split
set.seed(123)
indices <- createDataPartition(data_scaled$LSD_bin, p = 0.8, list = FALSE)
train <- data_scaled[indices, ]
test  <- data_scaled[-indices, ]

# Train neural network
drug_net <- neuralnet(
  formula,
  data          = train,
  hidden        = 3,               # three hidden neurons
  linear.output = FALSE,           # classification
  threshold     = 0.01,
  stepmax       = 1e6
)


```

```{r plot_net, echo=FALSE, fig.width=11, fig.height=6, dpi=150, fig.cap="Neural network with three hidden neurons", out.width='0.8\\linewidth'}
plotnet(drug_net,
        rel.ranking = TRUE,
        cex.val     = 0.6,
        col.hidden  = "lightblue",
        col.hidden.syn = "black",
        alpha       = 0.6,
        lwd         = 2)
```

```{r error_steps, echo=FALSE}
cat("Error:", round(drug_net$result.matrix["error", ], 2), "
")
cat("Steps:", drug_net$result.matrix["steps", ], "
")
```

**Error:** The training error is approximately 236.65, which reflects the residual error after training. This value indicates the degree to which the network's predictions deviate from the actual labels during training.

**Steps:** The network took around 22,306 steps (iterations) to converge, suggesting a thorough training process allowing the model to adjust its parameters carefully.

**Reached Threshold:** The training stopped when the error reached about 0.008, a strict convergence threshold indicating the network has largely stabilized.

**Input-to-Hidden Layer Weights:**
The weights between the input variables (personality traits, demographics) and the three hidden neurons indicate how each input influences the activation of each hidden neuron.

- Nscore (Neuroticism) has a strong negative weight on hidden neuron 1 (-35.1), a positive weight on neuron 2 (+13.5), and a small positive weight on neuron 3 (+0.31). This suggests that neuroticism impacts different hidden neurons in contrasting ways, reflecting complex, nonlinear relationships.
- Escore (Extraversion) shows a similarly strong negative influence on hidden neuron 1 (-40.8) and a smaller positive effect on neurons 2 and 3.
- Oscore (Openness) stands out with a large positive weight on hidden neuron 1 (+50.7) but negative on neuron 3 (-0.85), showing its strong but differentiated role in the network.
- Other traits like Impulsiveness, Sensation Seeking (SS), Age, Gender, and Education have varied weights, both positive and negative, indicating their nuanced contributions to hidden layer activations.

**Hidden-to-Output Layer Weights:**
The three hidden neurons connect to the outputs corresponding to LSD_bin, Ecstasy_bin, and Coke_bin (binary indicators for drug usage).

- For LSD_bin, the weights show that hidden neuron 2 has an extremely large negative effect (-2217.9), suggesting this neuron plays a pivotal role in predicting LSD use with strong suppression. Neuron 1 and 3 contribute less strongly.
- For Ecstasy_bin, hidden neuron 2 has a large positive weight (+2.37), while neurons 1 and 3 have negative weights, implying a complex pattern of interaction influencing ecstasy use prediction.
- For Coke_bin, neuron 2 again shows a strong positive effect (+7.29), suggesting it is a key driver for cocaine use prediction in the model.

**Note:** Black lines represent positive weights, and grey lines represent negative weights between neurons; thicker lines indicate stronger influence on the activation and final prediction.

**Intercepts:**
The intercepts for each hidden neuron and output node provide baseline activation levels, adjusting the network’s flexibility to fit the data.

**Insights**
The differential signs and magnitudes of weights connecting inputs to hidden neurons reveal the neural network's capacity to model nonlinear and complex interactions between personality traits, demographics, and drug use risk.

- The strong and extreme weights from hidden neurons to specific output nodes suggest that certain latent features captured in hidden layers are highly predictive of specific drug usages (e.g., neuron 2 for LSD and cocaine).
- Variables like Openness (Oscore) and Neuroticism (Nscore) appear as strong influencers, consistent with psychological theories linking these traits to substance use vulnerability.
- The diversity of weight signs (positive and negative) within the same trait across hidden neurons reflects the model's ability to capture nuanced behavioral patterns, possibly identifying different "risk pathways" or subgroups.
- The high number of training steps and low reached threshold suggest that the model has thoroughly learned the patterns in the training data, which supports trust in the model’s predictions.


Key personality traits like Neuroticism, Openness, and Sensation Seeking strongly influence risk, acting as both enhancers and mitigators across drugs. Demographics add essential context, enriching the risk profile. Based on the neural network's output weights, cocain is most likely to be the most strongly predicted follow-up drug when the hidden layers are activated. It receives the strongest positive influence (+7.29) from one of the hidden units (1layhid2), compared to weaker or negative influences on the others.

Practically, this approach supports personalized interventions by identifying individuals at high risk for specific substances, enabling targeted prevention and tailored messaging. Overall, it advances predictive analytics by integrating psychological and demographic factors to better understand and address substance use trajectories.

**Note:** While magnitude of weights gives insight, the activation functions (e.g., sigmoid or tanh) and input scaling affect final output, hence making interpretation more qualitative rather than exact.

### Predictions, Evaluation and Classification Insights

To assess the predictive performance of the trained neural network, we generated probabilistic outputs for each individual in the test set across the three target substances: LSD, Ecstasy, and Cocaine. These probabilities reflect the model’s confidence in recent drug use and were subsequently binarized using a 0.5 threshold. Individuals with predicted probabilities above this threshold were classified as likely users, while those below were classified as non-users.

The table below displays the top 10 predicted probabilities for each drug, based on individuals' personality and demographic profiles. Most of the values fall well below the 0.5 threshold, indicating that these individuals are predicted to be non-users for all three substances. Only one case (row 22) shows a probability exceeding 0.5 for both Ecstasy and Cocaine, suggesting the model identified a potential user based on the learned patterns. This distribution reflects the model's tendency to predict lower risk levels for the majority of test cases, in line with class prevalence.

```{r predictions_table, echo=FALSE, results='asis'}

# Define input variables
after_vars <- c("Nscore", "Escore", "Oscore", "Ascore", "Cscore",
                "Impulsive", "SS", "Age", "Gender", "Education")

# Select predictors from test set
pred_input <- dplyr::select(test, all_of(after_vars))

# Generate predictions from ANN
pred_results <- neuralnet::compute(drug_net, pred_input)
probs <- as.data.frame(pred_results$net.result)
colnames(probs) <- c("LSD_prob", "Ecstasy_prob", "Coke_prob")

# Binarize using threshold 0.5
pred_classes <- as.data.frame(probs > 0.5)

# Actual test labels
actual <- dplyr::select(test, LSD_bin, Ecstasy_bin, Coke_bin)

# Confusion matrix for LSD
conf_matrix_lsd <- confusionMatrix(
  factor(as.integer(pred_classes$LSD_prob), levels = c(0, 1)),
  factor(actual$LSD_bin, levels = c(0, 1))
)

knitr::kable(head(probs, 10), caption = "Predicted Probabilities (Top 10 Test Cases)")
```



```{r predictions_evaluation, echo=FALSE, results='asis', fig.show='hold', fig.width=7, fig.height=5}
# Automatically print model performance metrics
cat("```\n")
cat(paste0("   Accuracy : ", round(conf_matrix_lsd$overall["Accuracy"], 4), "\n"))
cat(paste0("   95% CI : (", 
           round(conf_matrix_lsd$overall["AccuracyLower"], 4), ", ", 
           round(conf_matrix_lsd$overall["AccuracyUpper"], 4), ")\n"))
cat(paste0("   No Information Rate : ", round(conf_matrix_lsd$overall["AccuracyNull"], 4), "\n"))
cat(paste0("   P-Value [Acc > NIR] : ", signif(conf_matrix_lsd$overall["AccuracyPValue"], 4), "\n\n"))
cat(paste0("   Kappa : ", round(conf_matrix_lsd$overall["Kappa"], 4), "\n\n"))
cat(paste0("   Mcnemar's Test P-Value : ", signif(conf_matrix_lsd$overall["McnemarPValue"], 4), "\n\n"))
cat(paste0("            Sensitivity : ", round(conf_matrix_lsd$byClass["Sensitivity"], 4), "\n"))
cat(paste0("            Specificity : ", round(conf_matrix_lsd$byClass["Specificity"], 4), "\n"))
cat(paste0("         Pos Pred Value : ", round(conf_matrix_lsd$byClass["Pos Pred Value"], 4), "\n"))
cat(paste0("         Neg Pred Value : ", round(conf_matrix_lsd$byClass["Neg Pred Value"], 4), "\n"))
cat(paste0("             Prevalence : ", round(conf_matrix_lsd$byClass["Prevalence"], 4), "\n"))
cat(paste0("         Detection Rate : ", round(conf_matrix_lsd$byClass["Detection Rate"], 4), "\n"))
cat(paste0("   Detection Prevalence : ", round(conf_matrix_lsd$byClass["Detection Prevalence"], 4), "\n"))
cat(paste0("      Balanced Accuracy : ", round(conf_matrix_lsd$byClass["Balanced Accuracy"], 4), "\n\n"))
cat(paste0("   'Positive' Class : ", conf_matrix_lsd$positive, "\n"))
cat("```\n")
```

The neural network achieved an accuracy of 68.3%, slightly above the no-information rate of 66.8%, but with a non-significant p-value (p = 0.3561), suggesting limited statistical confidence that the model outperforms random guessing. The sensitivity of 81.2% indicates that the model correctly identifies the majority of actual non-users (positive class: 0), while the specificity of 42.4% reflects a weaker ability to detect users. The positive predictive value of 73.9% suggests that most individuals predicted as non-users are indeed non-users, while the negative predictive value of 52.8% shows moderate accuracy in identifying users. The Kappa statistic of 0.25 indicates fair agreement beyond chance, and the balanced accuracy of 61.8% highlights the model's unequal performance between the two classes. Overall, the model performs reasonably well in identifying non-users but may require refinement to better capture true users.

To further evaluate the predictive performance of the neural network on the test set, a confusion matrix heatmap was generated. The matrix below illustrates the model’s classification accuracy for LSD use.

```{r predictions_evaluation2, echo=FALSE, results='asis', fig.show='hold', fig.width=3, fig.height=2}
# Prepare for heatmap
cm_df <- as.data.frame(conf_matrix_lsd$table)
colnames(cm_df) <- c("Predicted", "Actual", "Freq")
cm_df <- cm_df %>%
  mutate(
    Predicted = factor(Predicted, levels = c(0, 1)),
    Actual    = factor(Actual,    levels = c(0, 1))
  )

# Plot confusion matrix heatmap
ggplot(cm_df, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 6) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Confusion Matrix: LSD Prediction", x = "Actual", y = "Predicted") +
  theme_minimal()
```

The confusion matrix reveals 25 false positives (non-users predicted as users) and 38 false negatives (users predicted as non-users), reflecting room for improvement in classification balance.

Together, these results underscore the neural network’s ability to capture relevant patterns but also the challenges in accurately distinguishing non-users from users, likely due to the complex behavioral and psychological factors involved.


### Risk Group Identification

To better understand risk patterns, K-means clustering was applied to the neural network’s predicted probabilities for LSD, Ecstasy, and Cocaine use among cannabis users. This unsupervised approach segmented users into four clusters, each with distinct profiles of predicted drug involvement.

**Cluster Characteristics**
The table summarizes average substance-use probabilities per cluster:

```{r kmeans_segmentation, echo=FALSE, results='asis', fig.show='hold', fig.width=7, fig.height=5}
# K-means clustering on ANN probabilities
set.seed(123)
km <- kmeans(probs[, c("LSD_prob", "Ecstasy_prob", "Coke_prob")], centers = 4)

# Assign cluster numbers
probs$Cluster <- km$cluster

# Compute mean probabilities by cluster number
cluster_means <- probs %>%
  group_by(Cluster) %>%
  summarise(
    LSD_avg     = mean(LSD_prob),
    Ecstasy_avg = mean(Ecstasy_prob),
    Coke_avg    = mean(Coke_prob),
    .groups     = "drop"
  )

# Manually assign cluster labels based on known characteristics
label_map <- c("Low Risk", "Party-Prone", "Multi-Risk", "Psychedelic-Inclined")

# Ensure consistent ordering
probs$ClusterLabel <- factor(label_map[probs$Cluster], levels = label_map)

# Recalculate summary by cluster label
cluster_summary_named <- probs %>%
  group_by(ClusterLabel) %>%
  summarise(
    LSD_avg     = mean(LSD_prob),
    Ecstasy_avg = mean(Ecstasy_prob),
    Coke_avg    = mean(Coke_prob),
    .groups     = "drop"
  )

# Display table
knitr::kable(cluster_summary_named,
             caption = "Average predicted probabilities by user risk cluster",
             align   = 'c')
```

- Cluster 1 (“Low Risk”) has the lowest average probabilities, representing individuals with relatively minimal predicted follow-up use of these substances.
- Cluster 2 (“Party-Prone”) is characterized by moderate to high Ecstasy and Cocaine probabilities but comparatively low LSD risk, suggestive of users primarily engaged in social or recreational drug use.
- Cluster 3 (“Multi-Risk”) exhibits the highest average probabilities across all three substances, identifying a high-risk subgroup with broad susceptibility to polysubstance use.
- Cluster 4 (“Psychedelic-Inclined”) shows elevated predicted risk for LSD and Ecstasy but lower for Cocaine, indicating a focus on psychedelic and party drugs.

```{r kmeans_segmentation2, echo=FALSE, results='asis', fig.show='hold', fig.width=5, fig.height=4}
# Cluster scatter plot
ggplot(probs, aes(x = LSD_prob, y = Ecstasy_prob, color = ClusterLabel)) +
  geom_point(alpha = 0.7) +
  labs(title = "Labeled Cannabis User Clusters by Risk Type",
       x = "LSD Probability", y = "Ecstasy Probability") +
  theme_minimal()
```

The plot visualizes cannabis users grouped into four distinct clusters based on their predicted probabilities of LSD and Ecstasy use. The “Low Risk” group (red) clusters around the center with moderate but generally sub-threshold probabilities for both substances. The “Party-Prone” cluster (green) is concentrated in the bottom-left corner, showing low LSD probability and low-to-moderate Ecstasy probability. The “Multi-Risk” group (cyan) trends upward and to the right, indicating rising probabilities for both LSD and Ecstasy, reflecting elevated overall risk. Meanwhile, the “Psychedelic-Inclined” cluster (purple) is distinguished by high LSD involvement and moderate-to-high Ecstasy probability, emphasizing preference for hallucinogenic experiences.

This clustering structure reveals diverse drug-use trajectories among cannabis users and emphasizes the need for differentiated prevention strategies. For instance, Cluster 3 (Multi-Risk) may require broad-spectrum interventions targeting poly-substance risks, whereas Cluster 4 (Psychedelic-Inclined) could benefit from education focused on hallucinogen-specific effects and risks. Tailored responses based on cluster profiles can improve the efficacy of public health initiatives.


**Rule-Based Risk Segmentation and Trait Visualization**

To reinforce insights from clustering, a rule-based segmentation was performed using threshold logic applied to neural network probabilities. Each user was classified as:

- Multi-Risk: High probability (> 0.7) for both LSD and Ecstasy use — indicating a poly-substance risk profile.
- Psychedelic-Inclined: High LSD risk (> 0.7), but not Ecstasy.
- Party-Prone: High Ecstasy risk (> 0.7), but low LSD.
- Low Risk: Low probabilities (< 0.3) across all three substances.
- Other: Users who did not clearly meet any of the above thresholds.

To visualize and compare the typical traits associated with each risk group, we constructed a radar plot summarizing the average values of key psychological and demographic dimensions:

- Big Five traits: Neuroticism, Conscientiousness, Openness, Agreeableness, Extraversion
- Impulsiveness, Sensation Seeking
- Age, Gender, Education level


```{r trait_visuals, echo=FALSE, results='asis', fig.show='hold', fig.width=6, fig.height=5}
# Trait columns to include
trait_cols <- c("Nscore", "Cscore", "Oscore", "Ascore", "Escore", "Impulsive", "SS", "Age", "Gender", "Education")

probs <- probs %>%
  mutate(RuleGroup = case_when(
    LSD_prob > 0.7 & Ecstasy_prob > 0.7 ~ "Multi-Risk",
    LSD_prob > 0.7                     ~ "Psychedelic-Inclined",
    Ecstasy_prob > 0.7                 ~ "Party-Prone",
    LSD_prob < 0.3 & Ecstasy_prob < 0.3 & Coke_prob < 0.3 ~ "Low Risk",
    TRUE                               ~ "Other"
  ))


# Combine probabilities with corresponding trait values
traits_with_probs <- cbind(
  probs,
  test[, trait_cols]
)

# Average traits by rule‑based profile
radar_data <- traits_with_probs %>%
  group_by(RuleGroup) %>%
  summarise(across(all_of(trait_cols), mean), .groups = "drop") %>%
  column_to_rownames("RuleGroup")

# Scale 0–1 for radar plot
radar_scaled <- as.data.frame(t(apply(radar_data, 2, function(x) (x - min(x)) / (max(x) - min(x)))))
radar_scaled <- as.data.frame(t(radar_scaled))
radar_scaled <- rbind(rep(1, length(trait_cols)), rep(0, length(trait_cols)), radar_scaled)
colnames(radar_scaled) <- trait_cols
rownames(radar_scaled)[1:2] <- c("Max", "Min")

# Radar chart
radarchart(radar_scaled,
           axistype = 1,
           pcol     = rainbow(nrow(radar_data)),
           plwd     = 2,
           plty     = 1)

title("Personality Traits by Profile", cex.main = 0.9)

# Adjust legend position slightly closer
par(xpd = TRUE)
legend(x = 1.1, y = 1.1,
       legend = rownames(radar_data),
       col    = rainbow(nrow(radar_data)),
       lty    = 1, lwd = 2, bty = "n")
par(xpd = FALSE)
```
**Interpretation**

The radar plot offers a clear, multi-dimensional snapshot of how psychological and demographic characteristics vary across risk profiles:
- Multi-Risk users generally exhibit elevated levels of sensation seeking and impulsiveness, aligning with greater likelihoods of polydrug use.
- Psychedelic-Inclined individuals display higher openness and extraversion, consistent with prior research linking these traits to psychedelic drug experimentation.
- Party-Prone users score higher on extraversion and impulsiveness but show moderate openness.
- Low Risk individuals show consistently lower scores across risk-related traits, such as impulsiveness and sensation seeking, and tend to be older and more educated.
- Demographic traits such as age and education also differ subtly between profiles, providing additional context for intervention strategies.

### Trait-Drug Relationship Analysis

Finally, we implemented a  trait-drug relationship heatmap that visualizes the correlations between key personality traits and recent usage of LSD, Ecstasy, and Cocaine among cannabis users. By examining these relationships, we gain insight into how individual differences in psychological profiles relate to specific drug consumption risks.

```{r trait_heatmap, echo=FALSE, fig.width=6, fig.height=3.5}

corr_matrix <- cor(data_scaled[, c(trait_cols, "LSD_bin", "Ecstasy_bin", "Coke_bin")])
heat_data <- reshape2::melt(corr_matrix[trait_cols, c("LSD_bin", "Ecstasy_bin", "Coke_bin")])

# Swap axes: traits on x, drugs on y
heat_data$Var1 <- factor(heat_data$Var1, levels = trait_cols)
heat_data$Var2 <- factor(heat_data$Var2, levels = c("LSD_bin", "Ecstasy_bin", "Coke_bin"))

ggplot(heat_data, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(value, 2)), size = 2) +  # reduced from 5 → 3
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1, 1), space = "Lab",
                       name = "Correlation") +
  theme_minimal() +
  labs(title = "Trait–Drug Correlation Heatmap", x = "Trait", y = "Drug") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_fixed()



```

Key insights from the heatmap:

- Positive correlations (depicted in red hues) indicate traits that increase the likelihood of drug use, while negative correlations (blue hues) suggest protective or inverse relationships.
- Sensation Seeking (SS) shows consistent positive correlations with all three drugs, reinforcing its role as a strong risk factor for substance use.
- Age exhibits negative correlations with drug use, suggesting that younger individuals are more likely to engage in LSD, Ecstasy, and Cocaine consumption.
- Gender shows mild positive correlation with LSD and Ecstasy, which may reflect demographic patterns in drug use behaviors.
- Other personality traits display mostly weak or neutral correlations, indicating a complex interplay where certain traits contribute variably to risk profiles.


## Support Vector Machine (Thilo Holstein)

By focusing specifically on recent Cannabis users (within the past year or more recent), we narrow through a SVM model the analysis to a population at elevated risk for multi-drug use, thereby improving the model’s relevance and accuracy and ultimately revealing nuanced risk profiles.

This analysis employs support vector machines (SVM) to classify individuals based on their polydrug consumption patterns, focusing on identifying and profiling users according to the severity of their drug use.

```{r data_prep, echo=FALSE, cache=TRUE}

model_data <- read.csv("Data/model_data.csv")

# Define drug usage columns
drug_cols <- c("Coke", "LSD", "Ecstasy", "Ketamine", "Cannabis", "Alcohol", "Amphet")

# Convert to numeric
model_data[drug_cols] <- lapply(model_data[drug_cols], as.numeric)

# Create binary and multiclass targets safely
model_data <- model_data %>%
  mutate(
    drug_count = rowSums(dplyr::select(., all_of(drug_cols)) >= 3, na.rm = TRUE),
    PolyDrugUser = factor(ifelse(drug_count >= 3, "Yes", "No")),
    PolyDrugClass = case_when(
      drug_count == 0 ~ "None",
      drug_count < 3  ~ "Moderate",
      drug_count >= 3 ~ "Poly"
    ) %>% factor(levels = c("None", "Moderate", "Poly"))
  )

# Define predictors
predictors <- c("Nscore", "Cscore", "Oscore", "Ascore", "Escore",
                "Impulsive", "SS", "Age", "Gender", "Education",
                "Alcohol", "Cannabis")

# Drop rows with missing values in predictors or targets
data_clean <- model_data %>%
  tidyr::drop_na(all_of(c(predictors, "PolyDrugUser", "PolyDrugClass")))

# Train/test split
set.seed(123)
split_idx <- sample(seq_len(nrow(data_clean)), size = 0.8 * nrow(data_clean))

train_bin <- data_clean[split_idx, ]
train_mc  <- train_bin

test_bin  <- data_clean[-split_idx, ]
test_mc   <- test_bin
```

### Binary SVM Model

Key drug usage variables—including Cocaine, LSD, Ecstasy, Ketamine, Cannabis, Alcohol, and Amphetamines—were numerically encoded and binarized to capture recent use (a score of 3 or higher). A composite drug_count variable quantifies the number of substances used recently by each respondent, allowing us to label individuals as polydrug users if they report recent use of three or more substances.

The binary SVM model, leveraging a radial basis function kernel and probability, achieved strong performance, with an accuracy of approximately 85%, effectively distinguishing polydrug users from non-users. The confusion matrix reveals a balanced classification, with some misclassifications mostly between classes:


```{r svm_binary, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
svm_bin <- svm(
  as.formula(paste("PolyDrugUser ~", paste(predictors, collapse = "+"))),
  data   = train_bin,
  kernel = "radial",
  cost   = 1,
  scale  = TRUE,
  probability = TRUE
)

pred_bin_labels <- predict(svm_bin, test_bin)
prob_bin        <- attr(predict(svm_bin, test_bin, probability = TRUE), "probabilities")[, "Yes"]

test_bin <- test_bin %>% mutate(PredictedClass = pred_bin_labels,
                                PredictedProb  = prob_bin)

cm_bin <- table(Predicted = pred_bin_labels, Actual = test_bin$PolyDrugUser)
acc_bin <- mean(pred_bin_labels == test_bin$PolyDrugUser)
```

```{r svm_binary_table, echo=FALSE, results='asis'}

knitr::kable(cm_bin,
             caption = sprintf("Binary SVM Confusion Matrix (Accuracy = %.3f)", acc_bin),
             align = 'c') %>%
  kable_styling(latex_options = c("hold_position"))

```

### Multiclass SVM Model

To reflect the spectrum of substance use more accurately, a multi-class variable was created, categorizing respondents into “None,” “Moderate” (one or two drugs), or “Poly” (three or more drugs) user groups. Psychological traits such as impulsivity, sensation seeking, and the Big Five personality dimensions—alongside demographics like age, gender, and education—were included as predictors, with recent Alcohol and Cannabis use incorporated due to their relevance. Building on this, a multi-class SVM model was trained to predict the intensity of drug use across these categories, achieving an accuracy of approximately 83.0%. The corresponding confusion matrix is shown below.


```{r svm_multiclass, echo=FALSE}
# Multi-class SVM
svm_mc <- svm(
  as.formula(paste("PolyDrugClass ~", paste(predictors, collapse = "+"))),
  data   = train_mc,
  kernel = "radial",
  cost   = 1,
  scale  = TRUE
)

pred_mc   <- predict(svm_mc, test_mc)
pred_mc   <- factor(pred_mc, levels = levels(test_mc$PolyDrugClass))
actual_mc <- factor(test_mc$PolyDrugClass, levels = levels(test_mc$PolyDrugClass))

cm_mc  <- table(Predicted = pred_mc, Actual = actual_mc)
acc_mc <- mean(pred_mc == actual_mc)

# Multi-class SVM Confusion Matrix Table
knitr::kable(cm_mc,
             caption = sprintf("Multi‑class SVM Confusion Matrix (Accuracy = %.3f)", acc_mc),
             align = 'c') %>%
  kable_styling(latex_options = c("hold_position"))
```

While the model effectively classified most individuals, some misclassifications occur between moderate and poly users, reflecting the complex, overlapping nature of substance use patterns. The binary model’s prediction probabilities provide additional insight, allowing for risk stratification and supporting personalized interventions beyond simple class labels.

Overall, these machine learning models demonstrate the capacity to capture complex, nonlinear relationships between personality, demographics, and drug use behavior. By identifying distinct risk profiles, they provide a valuable foundation for targeted interventions and personalized public health strategies. Integrating psychological and demographic factors with advanced classification techniques advances our understanding of polydrug use and its underlying drivers.


### Top‑Risk Profile Simulation

To deepen our understanding of poly-drug use risk, we employed an extensive Monte Carlo–style sampling strategy. By drawing 100,000 synthetic individual profiles, each reflecting realistic and moderate trait values derived from the interquartile range of our dataset, we approximated a broad yet plausible population spectrum. This approach incorporates controlled variability through jittering, maintaining trait values within typical bounds while capturing natural fluctuations.

Key demographic and behavioral features—such as personality traits (e.g., Neuroticism, Conscientiousness, Openness, Agreeableness, Extraversion, Impulsiveness, Sensation Seeking), age categories, gender distribution, education levels, and alcohol/cannabis consumption—were sampled according to observed distributions and probabilities. Parallelized computation was used to efficiently predict poly-drug use risk for each synthetic profile based on the previously trained SVM model.


```{r simulate_profiles, echo=FALSE, results='asis', fig.show='hold'}
library(parallel)     # parallel utilities
library(kableExtra)   # nicer, scalable tables

# -------- Helper to sample realistic values --------
sample_trait_values <- function(trait, n = 1e5) {
  q <- quantile(trait, probs = c(0.25, 0.75), na.rm = TRUE)
  vals <- runif(n, q[1], q[2]) + rnorm(n, sd = 0.1)
  pmin(pmax(vals, q[1]), q[2])
}

n_samples <- 100000  # adjust if memory constrained

levels_moderate <- list(
  Nscore    = sample_trait_values(data_clean$Nscore, n_samples),
  Cscore    = sample_trait_values(data_clean$Cscore, n_samples),
  Oscore    = sample_trait_values(data_clean$Oscore, n_samples),
  Ascore    = sample_trait_values(data_clean$Ascore, n_samples),
  Escore    = sample_trait_values(data_clean$Escore, n_samples),
  Impulsive = sample_trait_values(data_clean$Impulsive, n_samples),
  SS        = sample_trait_values(data_clean$SS, n_samples),
  Age       = sample(1:6, n_samples, replace = TRUE),
  Gender    = sample(c(0, 1), n_samples, replace = TRUE, prob = c(0.4, 0.6)),
  Education = sample(c(2, 4, 5, 6, 7, 8), n_samples, replace = TRUE,
                     prob = c(0.05, 0.15, 0.3, 0.25, 0.15, 0.1)),
  Alcohol   = sample_trait_values(data_clean$Alcohol, n_samples),
  Cannabis  = sample_trait_values(data_clean$Cannabis, n_samples)
)

sampled_data <- as.data.frame(levels_moderate)

predict_svm <- function(model, newdata) as.numeric(predict(model, newdata) == "Yes")

# -------- Use predicted probabilities as risk --------

set.seed(1234)  # reproducible synthetic sampling

predict_prob <- function(model, newdata) {
  attr(predict(model, newdata, probability = TRUE), "probabilities")[, "Yes"]
}

cl <- parallel::makeCluster(max(1, parallel::detectCores() - 1))
parallel::clusterExport(cl, varlist = c("svm_bin", "predict_prob", "sampled_data"))
invisible(parallel::clusterEvalQ(cl, {library(e1071); NULL}))

predicted_risks <- parallel::parApply(cl, sampled_data, 1, function(row) {
  predict_prob(svm_bin, as.data.frame(t(row)))
})
parallel::stopCluster(cl)

sampled_data$PredictedRisk <- predicted_risks

# -------- Top‑3 profiles --------

top_profiles <- sampled_data %>%
  arrange(desc(PredictedRisk)) %>%
  head(3) %>%
  mutate(
    Gender_label = ifelse(Gender == 1, "Male", "Female"),
    Education_label = case_when(
      Education == 1 ~ "<16 years",
      Education == 2 ~ "16 years",
      Education == 3 ~ "17 years",
      Education == 4 ~ "18 years",
      Education == 5 ~ "Some college",
      Education == 6 ~ "Prof. diploma",
      Education == 7 ~ "University",
      Education == 8 ~ "Masters",
      Education == 9 ~ "Doctorate",
      TRUE ~ "Unknown"
    ),
    Profile = paste("Profile", row_number())
  )

# Split into traits and demographics
traits <- dplyr::select(top_profiles, Nscore, Cscore, Oscore, Ascore, Escore, Impulsive, SS, PredictedRisk)
demographics <- dplyr::select(top_profiles, Age, Gender, Education, Alcohol, Cannabis)

# Output both tables with styling
knitr::kable(traits, caption = "Top 3 High-Risk Profiles – Traits and Risk", align = 'c') %>%
  kable_styling(latex_options = "hold_position", font_size = 7)

knitr::kable(demographics, caption = "Top 3 High-Risk Profiles – Demographics and Substance Use", align = 'c') %>%
  kable_styling(latex_options = "hold_position", font_size = 7)

```

The top three profiles identified by the model share several notable characteristics:

- Personality Traits: Moderately high scores in Openness, Agreeableness, and Sensation Seeking suggest these individuals have a propensity for novel experiences and social engagement, both of which may facilitate substance experimentation.
- Demographics: All are males aged in the lower age brackets, consistent with known higher risk among younger males.
- Education: Uniformly classified as “Left school at 18 years,” indicating a particular educational attainment pattern associated with elevated risk.
- Alcohol and Cannabis Consumption: These profiles reflect higher average consumption levels, further compounding risk.

Each profile shows a predicted probability of poly-drug use exceeding 94.9%, underscoring the model’s confidence in these risk segments.

This sampling and profiling method transcends simple point predictions by simulating a nuanced population distribution, enabling the identification of high-risk multi-drug users that might be missed in direct observational studies. Such insights allow for targeted prevention strategies tailored to demographic and personality profiles most vulnerable to poly-drug behaviors. Moreover, the use of parallel computing ensures scalability and efficiency in handling large simulated datasets, making this approach robust for practical deployment.

### Explainability with SHAP Logic

To interpret the predictive drivers behind the model’s classification, we applied SHAP (Shapley Additive Explanations) values to a single high-risk individual identified by the SVM model with the highest predicted probability (0.96) of poly-drug use. The SHAP plot visually decomposes this prediction into contributions from each feature, revealing the relative importance and direction of effect on the risk score.

```{r shap_explain, echo=FALSE, fig.width=3.5, fig.height=2.5, fig.show='asis'}
if (exists("prob_bin")) {
  predict_prob <- function(model, newdata) {
    attr(predict(model, newdata, probability = TRUE), "probabilities")[, "Yes"]
  }

  explainer <- Predictor$new(
    model = svm_bin,
    data  = train_bin[, predictors],
    y     = train_bin$PolyDrugUser,
    predict.function = predict_prob,
    type  = "prob"
  )

  idx  <- which.max(prob_bin)
  shap <- Shapley$new(explainer, x.interest = test_bin[idx, predictors])

  # Plot with smaller title
  library(ggplot2)
  shap_plot <- plot(shap) +
    ggtitle("SHAP Explanation for Highest-Risk Individual") +
    theme(plot.title = element_text(size = 9))  # <- Adjust title size here

  print(shap_plot)
}
```

Notably, recent Cannabis use (coded as 6) is the most influential factor, strongly elevating the predicted risk. This aligns with its known role as a gateway substance. Age = 1, representing the youngest age group in the dataset, is the next most significant contributor, suggesting younger individuals face higher risk. Elevated Alcohol consumption (5) also adds substantially to risk, highlighting polysubstance tendencies. Personality traits like Sensation Seeking (SS = 0.77) and Impulsiveness (0.88) further amplify risk, consistent with psychological theories linking these traits to substance experimentation and abuse.
Conversely, some traits such as Agreeableness (-1.48) and Gender (0) have minor negative contributions, slightly mitigating risk in this profile. Overall, this SHAP breakdown affords a transparent understanding of the complex interplay of demographics, personality, and substance use behaviors driving individual risk predictions.
This analysis underscores the value of explainable AI techniques in elucidating “why” a person is flagged as high-risk, facilitating targeted interventions tailored to specific risk factors rather than a “black box” prediction. By quantifying and visualizing feature-level impacts, it also aids researchers and clinicians in validating model findings against domain knowledge.


**Highest-Risk Individual (Test Set Analysis)**

```{r shap_explain2, echo=FALSE, fig.width=4, fig.height=3, fig.show='asis'}
# Index of the highest-risk individual
idx <- which.max(prob_bin)

# Full profile
individual_row <- test_bin[idx, predictors, drop = FALSE]
individual_row$PredictedRisk <- round(prob_bin[idx], 4)

# Traits and demographics subsets
trait_cols <- c("Nscore", "Cscore", "Oscore", "Ascore", "Escore", "Impulsive", "SS")
demo_cols  <- c("Age", "Gender", "Education", "Alcohol", "Cannabis", "PredictedRisk")

# Tables
traits_table <- individual_row[, trait_cols, drop = FALSE]
demo_table   <- individual_row[, demo_cols, drop = FALSE]

# Table 1: Traits
knitr::kable(traits_table,
             caption = "Psychological Traits of the Highest-Risk Individual",
             align   = 'c') %>%
  kableExtra::kable_styling(latex_options = "hold_position", font_size = 8)
# Table 2: Demographics & Risk
knitr::kable(demo_table,
             caption = "Demographic Attributes and Predicted Risk",
             align   = 'c') %>%
  kableExtra::kable_styling(latex_options = "hold_position", font_size = 8)

```

Above's individual was flagged by the SVM classifier as the highest-risk poly-drug user, with a predicted probability of 0.9568, indicating very high model confidence.

Trait Profile:

- High Neuroticism (Nscore: 1.49) and low Agreeableness (Ascore: -1.48) suggest emotional instability and potential resistance to social norms.
- Low Conscientiousness (Cscore: -1.14) reflects impulsivity and low self-discipline, often associated with risky behavior.
- High Openness (Oscore: 1.06) and elevated Sensation Seeking (SS: 0.77) align with curiosity and thrill-seeking—traits frequently linked to experimentation.
- Impulsivity is elevated (0.88), further increasing risk.
- Age: 1 (likely young adult), Gender: 0 (possibly female), and Education: 6 (likely moderate to high).
- High recent use of Alcohol (5) and Cannabis (6) suggests active substance involvement.

**Interpretation**

This individual’s combination of high openness, low conscientiousness, and strong impulsive/sensation-seeking tendencies makes them a prototypical profile for high-risk behavior. Coupled with recent substance use, their psychological and behavioral pattern aligns with the model's confident classification.

# How we used Generative AI in our project

We applied generative AI throughout our R-based group work, asking it to craft tidyverse pipelines, debug “object not found” or “unexpected symbol” errors, and even rewrite ggplot2 calls for cleaner visuals and kable table for a better visual of tables. It was incredibly fast at generating correct snippets and clear explanations of statistical concepts. However, it sometimes scoped out of project-specific data structures or suggested functions that didn’t exist in our library versions—issues we could only catch by running and inspecting the code ourselves. We found it easy to get solutions, harder to adapt those solutions to our unique dataset, and occasionally impossible to force the AI to understand the context of the research questions which could be because of our prompt. To stay on track, we always cross-checked its answers, tested every suggested change in our scripts, and remained skeptical of any fixes that is without a proper logic.

# Conclusion

Overall, our analyses concludes that cannabis use is most strongly driven by individual differences in Sensation Seeking and Openness, with higher scores on these traits associated with both greater likelihood of ever trying cannabis and more frequent use. Conscientiousness and Agreeableness demonstrate consistently as protective factors: more disciplined individuals are less likely to initiate or regularly consume cannabis. Age has a pronounced negative main effect, cannabis use peaks in early adulthood and declines afterwards. Men report higher frequency of use than women, even after accounting for personality, and impulsivity plays a stronger role. Educational level shapes both the baseline probability of use and its age trajectory: the education groups (e.g., those leaving school at 18 or current students) show early‐adult peaks, whereas higher‐degree holders exhibit lower initiation rates and flatter age curves. Interaction tests further indicate that the influence of Sensation Seeking and Openness varies by age and gender, underscoring the conditional nature of these risk factors. In sum, cannabis consumption is best understood as the product used most by traits Sensation Seeking and Openess. Not only that, but also have a impact based on the educational position as well as stages of lifeline.

# Source

<https://archive.ics.uci.edu/dataset/373/drug+consumption+quantified>
